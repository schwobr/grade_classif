# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_predict.ipynb (unless otherwise specified).

__all__ = ['predict_one_scan_one_level', 'predict_one_scan', 'predict_all', 'predict_all_majority_vote', 'get_preds',
           'get_slide_heatmap_cancer_detection', 'get_folder_heatmaps_cancer_detection', 'get_slide_heatmap_binary',
           'get_folder_heatmaps_binary']

# Cell
from .core import ifnone
from .data.read import get_scan
from .data.dataset import TestDataset
from .data.utils import load_batches
from .models.plmodules import ImageClassifModel
from .imports import *
from torch.utils.data import DataLoader
from openslide import OpenSlide
from skimage.color import hsv2rgb
from fastai.data.transforms import get_files
import PIL.Image as Image

# Cell
def predict_one_scan_one_level(
    model: ImageClassifModel, fn: Path, thrs: Optional[float] = None
) -> Union[float, NDArray[(Any,), float]]:
    preds = []
    for x in load_batches(fn, bs=model.bs, device=model.main_device, filt=model.filt):
        preds.append(model.predict(x).detach().cpu()[:, -1])
    try:
        preds = torch.cat(preds)
    except:
        preds = torch.tensor([1.0])
    if thrs is None:
        return preds.sum().item() / len(preds)
    else:
        return (preds[None] > thrs[:, None]).sum(-1).numpy() / len(preds)

# Cell
def predict_one_scan(hparams: Namespace) -> float:
    hparams = vars(hparams)
    preds = []
    for level, version, norm_version in zip(
        hparams.levels, hparams.versions, hparams.norm_versions
    ):
        hparams.level = level
        hparams.norm_version = norm_version
        model = GradesClassifModel(**hparams)
        model.load(version)
        path = get_scan(
            hparams.full_data / f"{hparams.full_data.name}_{level}",
            hparams.scan,
            include=["1", "3"],
        )
        preds.append(predict_one_scan_one_level(model, path))
    preds = torch.cat(preds)
    return preds.sum().item() / len(preds)

# Cell
def predict_all(hparams: Namespace) -> pd.DataFrame:
    hparams = vars(hparams)
    df = pd.read_csv(hparams.data_csv, header="infer")
    preds = []
    scans = []
    levels = []
    for level, version, ckpt, norm_version in zip(
        hparams.levels, hparams.versions, hparams.checkpoints, hparams.norm_versions
    ):
        hparams.level = level
        hparams.norm_version = norm_version
        model = GradesClassifModel(**hparams)
        model.load(version, ckpt)
        for row in tqdm(df.loc[df["split"] == "valid"].values):
            scan, grade = row[:-1]
            fn = (
                hparams.full_data
                / f"{hparams.full_data.name}_{level}"
                / str(grade)
                / scan
            )
            try:
                preds.append(predict_one_scan_one_level(model, fn))
            except FileNotFoundError:
                continue
            scans.append(scan)
            levels.append(level)
    res = pd.DataFrame({"level": levels, "scan": scans, "pred": preds})
    return res

# Cell
def predict_all_majority_vote(
    hparams: Namespace,
) -> Tuple[List[str], List[int], NDArray[(Any, Any), float]]:
    hparams = vars(hparams)
    df = pd.read_csv(hparams.data_csv, header="infer")
    preds = []
    scans = []
    levels = []
    thrs = torch.tensor([0.001 * k for k in range(1000)])
    for level, version, ckpt, norm_version in zip(
        hparams.levels, hparams.versions, hparams.checkpoints, hparams.norm_versions
    ):
        hparams.level = level
        hparams.norm_version = norm_version
        model = GradesClassifModel(**hparams)
        model.load(version, ckpt)
        for row in tqdm(df.loc[df["split"] == "valid"].values):
            scan, grade = row[:-1]
            fn = (
                hparams.full_data
                / f"{hparams.full_data.name}_{level}"
                / str(grade)
                / scan
            )
            try:
                pred = predict_one_scan_one_level(model, fn, thrs=thrs)
            except FileNotFoundError:
                continue
            preds.append(pred)
            scans.append(scan)
            levels.append(level)
    return scans, levels, np.array(preds).T

# Cell
def get_preds(patchfolder, modelfile, device=0):
    device = torch.device(f"cuda:{device}")
    model = torch.jit.load(
            str(modelfile),
            map_location=device,
        ).eval()

    for p in model.parameters():
        p.requires_grad = False

    files = get_files(patchfolder, extensions=[".png"]).filter(
        lambda x: x.stem != "thumbnail"
    )
    ds = TestDataset(files)
    dl = DataLoader(
        ds, batch_size=8, shuffle=False, num_workers=4, drop_last=False, pin_memory=True
    )

    preds = []
    for x in tqdm(dl):
        x = x.to(device, non_blocking=True)
        with torch.cuda.amp.autocast():
            y = model(x).detach()
            y = torch.softmax(y, dim=1)
        preds.append(y.cpu())
    preds = torch.cat(preds)
    return np.array(files), preds.numpy()

# Cell
def get_slide_heatmap_cancer_detection(
    slidefile,
    outfolder,
    size=299,
    level=1,
    patchfolder=None,
    modelfile=None,
    predfile=None,
    device=0,
    resize_ratio=4,
    blend_alpha=0.4,
):
    assert predfile is not None or (modelfile is not None and patchfolder is not None)
    slidename = slidefile.stem
    if predfile is None:
        files, preds = get_preds(patchfolder, modelfile, device=device)
    else:
        df = pd.read_csv(predfile)
        files = np.vectorize(Path)(df.values[:, 0])
        idxs = np.vectorize(lambda x: x.parent.name)(files) == slidename
        files = files[idxs]
        if not len(files):
            return
        preds = df.values[idxs, -3:].astype(np.float32)

    slide = OpenSlide(str(slidefile))
    if len(files[0].name.split("_")) > 3:
        x_coords = np.vectorize(lambda x: int(x.stem.split("_")[-2]))(
            files
        )
        y_coords = np.vectorize(lambda x: int(x.stem.split("_")[-1]))(
            files
        )
    else:
        x_coords = np.vectorize(lambda x: int(x.stem.split("_")[0]))(files)
        y_coords = np.vectorize(lambda x: int(x.stem.split("_")[1]))(files)
    unique_x = np.unique(x_coords)
    unique_x.sort()
    delta = (unique_x[1:]-unique_x[:-1]).min()
    w = int((slide.dimensions[0] - (size - delta)) / delta)
    h = int((slide.dimensions[1] - (size - delta)) / delta)
    x_coords = x_coords // delta
    y_coords = y_coords // delta
    labels = preds.argmax(axis=1)

    mask = np.zeros((h, w, 3), dtype=np.float64)
    idxs = np.argwhere(labels == 0)
    mask[(y_coords[idxs], x_coords[idxs])] = [0, 0, 0.5]
    idxs = np.argwhere(labels != 0)
    hues = 2 / 3 + 1 / 3 * preds[idxs, 1] / (preds[idxs, 1] + preds[idxs, 2])
    mask[(y_coords[idxs], x_coords[idxs])] = np.stack(
        (hues, np.ones_like(idxs), np.ones_like(idxs)), axis=-1
    )
    mask = hsv2rgb(mask)
    mask = Image.fromarray((mask * 255).astype(np.uint8)).resize(
        (w * resize_ratio, h * resize_ratio)
    )
    thumb = slide.get_thumbnail(mask.size).resize(mask.size)
    heatmap = Image.blend(thumb, mask, blend_alpha)

    outfolder = Path(outfolder)
    if not outfolder.exists():
        outfolder.mkdir(parents=True)
    mask.save(outfolder / f"{slidename}_mask.png")
    heatmap.save(outfolder / f"{slidename}_heatmap.png")

# Cell
def get_folder_heatmaps_cancer_detection(
    slidefolder,
    outfolder,
    size=299,
    level=1,
    patchfolder=None,
    modelfile=None,
    predfile=None,
    device=0,
    resize_ratio=4,
    blend_alpha=0.4,
):
    assert predfile is not None or (modelfile is not None and patchfolder is not None)
    for slidefile in Path(slidefolder).iterdir():
        if slidefile.is_file():
            print(slidefile.stem)
            if patchfolder is not None:
                slide_patchfolder = Path(patchfolder) / slidefile.stem
                if not slide_patchfolder.exists():
                    continue
            else:
                slide_patchfolder = None
            get_slide_heatmap_cancer_detection(
                slidefile,
                outfolder,
                size=size,
                level=level,
                patchfolder=slide_patchfolder,
                modelfile=modelfile,
                predfile=predfile,
                device=device,
                resize_ratio=resize_ratio,
                blend_alpha=blend_alpha
            )

# Cell
def get_slide_heatmap_binary(
    slidefile,
    outfolder,
    size=299,
    level=1,
    patchfolder=None,
    modelfile=None,
    predfile=None,
    device=0,
    resize_ratio=4,
    blend_alpha=0.4,
):
    assert predfile is not None or (modelfile is not None and patchfolder is not None)
    slidename = slidefile.stem
    if predfile is None:
        files, preds = get_preds(patchfolder, modelfile, device=device)
    else:
        df = pd.read_csv(predfile)
        files = np.vectorize(Path)(df.values[:, 0])
        idxs = np.vectorize(lambda x: x.parent.name)(files) == slidename
        files = files[idxs]
        if not len(files):
            return
        preds = df.values[idxs, -2:].astype(np.float32)

    slide = OpenSlide(str(slidefile))
    if len(files[0].name.split("_")) > 3:
        x_coords = np.vectorize(lambda x: int(x.stem.split("_")[-2]))(
            files
        )
        y_coords = np.vectorize(lambda x: int(x.stem.split("_")[-1]))(
            files
        )
    else:
        x_coords = np.vectorize(lambda x: int(x.stem.split("_")[0]))(files)
        y_coords = np.vectorize(lambda x: int(x.stem.split("_")[1]))(files)
    unique_x = np.unique(x_coords)
    unique_x.sort()
    delta = (unique_x[1:]-unique_x[:-1]).min()
    w = int((slide.dimensions[0] - (size - delta)) / delta)
    h = int((slide.dimensions[1] - (size - delta)) / delta)
    x_coords = x_coords // delta
    y_coords = y_coords // delta
    labels = preds.argmax(axis=1)

    mask = np.zeros((h, w, 3), dtype=np.float64)
    hues = 2 / 3 + 1 / 3 * preds[:, 1]
    mask[(y_coords, x_coords)] = np.stack(
        (hues, np.ones_like(hues), np.ones_like(hues)), axis=-1
    )
    mask = hsv2rgb(mask)
    mask = Image.fromarray((mask * 255).astype(np.uint8)).resize(
        (w * resize_ratio, h * resize_ratio)
    )
    thumb = slide.get_thumbnail(mask.size).resize(mask.size)
    heatmap = Image.blend(thumb, mask, blend_alpha)

    outfolder = Path(outfolder)
    if not outfolder.exists():
        outfolder.mkdir(parents=True)
    mask.save(outfolder / f"{slidename}_mask.png")
    heatmap.save(outfolder / f"{slidename}_heatmap.png")

# Cell
def get_folder_heatmaps_binary(
    slidefolder,
    outfolder,
    size=299,
    level=1,
    patchfolder=None,
    modelfile=None,
    predfile=None,
    device=0,
    resize_ratio=4,
    blend_alpha=0.4,
):
    assert predfile is not None or (modelfile is not None and patchfolder is not None)
    for slidefile in Path(slidefolder).iterdir():
        if slidefile.is_file():
            print(slidefile.stem)
            if patchfolder is not None:
                slide_patchfolder = Path(patchfolder) / slidefile.stem
                if not slide_patchfolder.exists():
                    continue
            else:
                slide_patchfolder = None
            get_slide_heatmap_binary(
                slidefile,
                outfolder,
                size=size,
                level=level,
                patchfolder=slide_patchfolder,
                modelfile=modelfile,
                predfile=predfile,
                device=device,
                resize_ratio=resize_ratio,
                blend_alpha=blend_alpha
            )