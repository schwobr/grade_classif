---

title: Title
keywords: fastai
sidebar: home_sidebar

summary: "summary"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/20_models.plmodules.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>//home/DeepLearning/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)])
//home/DeepLearning/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)])
//home/DeepLearning/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)])
//home/DeepLearning/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)])
//home/DeepLearning/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)])
//home/DeepLearning/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BaseModule" class="doc_header"><code>class</code> <code>BaseModule</code><a href="https://github.com/schwobr/grade_classif/tree/master/grade_classif/models/plmodules.py#L47" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BaseModule</code>(<strong><code>hparams</code></strong>, <strong><code>metrics</code></strong>=<em><code>None</code></em>) :: <code>LightningModule</code></p>
</blockquote>
<p>A LightningModule has the following properties which you can access at any time</p>
<p><strong>logger</strong>
A reference to the logger you passed into trainer.
Passing a logger is optional. If you don't pass one in, Lightning will create one
 for you automatically. This logger saves logs to <code>/os.getcwd()/lightning_logs</code>::</p>

<pre><code>Trainer(logger=your_logger)


</code></pre>
<p>Call it from anywhere in your LightningModule to add metrics, images, etc...
 whatever your logger supports.</p>
<p>Here is an example using the TestTubeLogger (which is a wrapper
 on 'PyTorch SummaryWriter <a href="https://pytorch.org/docs/stable/tensorboard.html">https://pytorch.org/docs/stable/tensorboard.html</a>`_
 with versioned folder structure).</p>
<p>.. code-block:: python</p>

<pre><code># if logger is a tensorboard logger or TestTubeLogger
self.logger.experiment.add_embedding(...)
self.logger.experiment.log({'val_loss': 0.9})
self.logger.experiment.add_scalars(...)


</code></pre>
<p><strong>trainer</strong>
Last resort access to any state the trainer has.
 Changing certain properties here could affect your training run.</p>
<p>.. code-block:: python</p>

<pre><code>self.trainer.optimizers
self.trainer.current_epoch
...

</code></pre>
<h2 id="Debugging">Debugging<a class="anchor-link" href="#Debugging">&#182;</a></h2><p>The LightningModule also offers these tricks to help debug.</p>
<p><strong>example_input_array</strong></p>
<p>In the LightningModule init, you can set a dummy tensor for this property
to get a print out of sizes coming into and out of every layer.</p>
<p>.. code-block:: python</p>

<pre><code>def __init__(self):
    # put the dimensions of the first input to your system
    self.example_input_array = torch.rand(5, 28 * 28)</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GradesClassifModel" class="doc_header"><code>class</code> <code>GradesClassifModel</code><a href="https://github.com/schwobr/grade_classif/tree/master/grade_classif/models/plmodules.py#L169" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GradesClassifModel</code>(<strong><code>hparams</code></strong>) :: <a href="models.plmodules.html#BaseModule"><code>BaseModule</code></a></p>
</blockquote>
<p>A LightningModule has the following properties which you can access at any time</p>
<p><strong>logger</strong>
A reference to the logger you passed into trainer.
Passing a logger is optional. If you don't pass one in, Lightning will create one
 for you automatically. This logger saves logs to <code>/os.getcwd()/lightning_logs</code>::</p>

<pre><code>Trainer(logger=your_logger)


</code></pre>
<p>Call it from anywhere in your LightningModule to add metrics, images, etc...
 whatever your logger supports.</p>
<p>Here is an example using the TestTubeLogger (which is a wrapper
 on 'PyTorch SummaryWriter <a href="https://pytorch.org/docs/stable/tensorboard.html">https://pytorch.org/docs/stable/tensorboard.html</a>`_
 with versioned folder structure).</p>
<p>.. code-block:: python</p>

<pre><code># if logger is a tensorboard logger or TestTubeLogger
self.logger.experiment.add_embedding(...)
self.logger.experiment.log({'val_loss': 0.9})
self.logger.experiment.add_scalars(...)


</code></pre>
<p><strong>trainer</strong>
Last resort access to any state the trainer has.
 Changing certain properties here could affect your training run.</p>
<p>.. code-block:: python</p>

<pre><code>self.trainer.optimizers
self.trainer.current_epoch
...

</code></pre>
<h2 id="Debugging">Debugging<a class="anchor-link" href="#Debugging">&#182;</a></h2><p>The LightningModule also offers these tricks to help debug.</p>
<p><strong>example_input_array</strong></p>
<p>In the LightningModule init, you can set a dummy tensor for this property
to get a print out of sizes coming into and out of every layer.</p>
<p>.. code-block:: python</p>

<pre><code>def __init__(self):
    # put the dimensions of the first input to your system
    self.example_input_array = torch.rand(5, 28 * 28)</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Normalizer" class="doc_header"><code>class</code> <code>Normalizer</code><a href="https://github.com/schwobr/grade_classif/tree/master/grade_classif/models/plmodules.py#L212" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Normalizer</code>(<strong><code>hparams</code></strong>) :: <a href="models.plmodules.html#BaseModule"><code>BaseModule</code></a></p>
</blockquote>
<p>A LightningModule has the following properties which you can access at any time</p>
<p><strong>logger</strong>
A reference to the logger you passed into trainer.
Passing a logger is optional. If you don't pass one in, Lightning will create one
 for you automatically. This logger saves logs to <code>/os.getcwd()/lightning_logs</code>::</p>

<pre><code>Trainer(logger=your_logger)


</code></pre>
<p>Call it from anywhere in your LightningModule to add metrics, images, etc...
 whatever your logger supports.</p>
<p>Here is an example using the TestTubeLogger (which is a wrapper
 on 'PyTorch SummaryWriter <a href="https://pytorch.org/docs/stable/tensorboard.html">https://pytorch.org/docs/stable/tensorboard.html</a>`_
 with versioned folder structure).</p>
<p>.. code-block:: python</p>

<pre><code># if logger is a tensorboard logger or TestTubeLogger
self.logger.experiment.add_embedding(...)
self.logger.experiment.log({'val_loss': 0.9})
self.logger.experiment.add_scalars(...)


</code></pre>
<p><strong>trainer</strong>
Last resort access to any state the trainer has.
 Changing certain properties here could affect your training run.</p>
<p>.. code-block:: python</p>

<pre><code>self.trainer.optimizers
self.trainer.current_epoch
...

</code></pre>
<h2 id="Debugging">Debugging<a class="anchor-link" href="#Debugging">&#182;</a></h2><p>The LightningModule also offers these tricks to help debug.</p>
<p><strong>example_input_array</strong></p>
<p>In the LightningModule init, you can set a dummy tensor for this property
to get a print out of sizes coming into and out of every layer.</p>
<p>.. code-block:: python</p>

<pre><code>def __init__(self):
    # put the dimensions of the first input to your system
    self.example_input_array = torch.rand(5, 28 * 28)</code></pre>

</div>

</div>

</div>
</div>

</div>
</div>
 

