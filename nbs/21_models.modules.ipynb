{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Modules\n",
    "> All layers and modules directly defined using <code>torch.nn.Module</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.models.utils import get_sizes\n",
    "from grade_classif.models.hooks import Hooks\n",
    "from grade_classif.imports import *\n",
    "from torch.nn.functional import interpolate, pad\n",
    "from timm.models.layers.adaptive_avgmax_pool import SelectAdaptivePool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def bn_drop_lin(n_in, n_out, bn=True, p=0., actn=None):\n",
    "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "    if p != 0: layers.append(nn.Dropout(p))\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if actn is not None: layers.append(actn)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn` (if specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, bias=True, eps=1e-5, momentum=0.01, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, stride=stride,\n",
    "            padding=padding, bias=bias, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            out_channels, eps=eps, momentum=momentum)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ConvBn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, bias=True, eps=1e-5, momentum=0.01, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, stride=stride,\n",
    "            padding=padding, bias=bias, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            out_channels, eps=eps, momentum=momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "            bias=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, stride=stride,\n",
    "            padding=padding, bias=bias, **kwargs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def icnr(x, scale=2, init=nn.init.kaiming_normal_):\n",
    "    ni, nf, h, w = x.shape\n",
    "    ni2 = int(ni/(scale**2))\n",
    "    k = init(torch.zeros([ni2, nf, h, w])).transpose(0, 1)\n",
    "    k = k.contiguous().view(ni2, nf, -1)\n",
    "    k = k.repeat(1, 1, scale**2)\n",
    "    k = k.contiguous().view([nf, ni, h, w]).transpose(0, 1)\n",
    "    x.data.copy_(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PixelShuffleICNR(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels, out_channels, bias=True, scale_factor=2, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels*scale_factor**2, 1, bias=bias, **kwargs)\n",
    "        icnr(self.conv.weight)\n",
    "        self.shuf = nn.PixelShuffle(scale_factor)\n",
    "        # self.pad = nn.ReflectionPad2d((1, 0, 1, 0))\n",
    "        # self.blur = nn.AvgPool2d(2, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.shuf(x)\n",
    "        # x = self.pad(x)\n",
    "        # x = self.blur(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_chans, skip_chans, hook, final_div=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.hook = hook\n",
    "        self.shuf = PixelShuffleICNR(in_chans, in_chans//2, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(skip_chans)\n",
    "        ni = in_chans//2 + skip_chans\n",
    "        nf = ni if not final_div else skip_chans\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = ConvBnRelu(ni, nf, 3, padding=1, **kwargs)\n",
    "        self.conv2 = ConvBnRelu(nf, nf, 3, padding=1, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skipco = self.hook.stored\n",
    "        x = self.shuf(x)\n",
    "        ssh = skipco.shape[-2:]\n",
    "        if ssh != x.shape[-2:]:\n",
    "            x = interpolate(x, ssh, mode='nearest')\n",
    "        x = self.relu(torch.cat([x, self.bn(skipco)], dim=1))\n",
    "        return self.conv2(self.conv1(x))\n",
    "    \n",
    "class LastCross(nn.Module):\n",
    "    def __init__(self, n_chans, bottle=False):\n",
    "        super(LastCross, self).__init__()\n",
    "        n_mid = n_chans//2 if bottle else n_chans\n",
    "        self.conv1 = ConvBnRelu(n_chans, n_mid, 3, padding=1)\n",
    "        self.conv2 = ConvBnRelu(n_mid, n_chans, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CBR(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, n_kernels, n_layers, n_classes=2):\n",
    "        super().__init__()\n",
    "        in_c = 3\n",
    "        out_c = n_kernels\n",
    "        for k in range(n_layers):\n",
    "            self.add_module(f'cbr{k}', ConvBnRelu(in_c, out_c, kernel_size, stride=2, padding=kernel_size//2, padding_mode='reflect'))\n",
    "            # self.add_module(f'maxpool{k}', nn.MaxPool2d(3, stride=2, padding=1))\n",
    "            in_c = out_c\n",
    "            out_c *= 2\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat = nn.Flatten(-2, -1)\n",
    "        self.fc = nn.Linear(out_c, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.children():\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a basic CNN using a sequence of `n_layers` Conv-BatchNorm-ReLU. Conv layers use kernels of size `kernel_size` and have width doubled each time, initial width being `n_kernels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBR(\n",
       "  (cbr0): ConvBnRelu(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), padding_mode=reflect)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (cbr1): ConvBnRelu(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), padding_mode=reflect)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (cbr2): ConvBnRelu(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), padding_mode=reflect)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (cbr3): ConvBnRelu(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), padding_mode=reflect)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flat): Flatten()\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBR(7, 32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SelfAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, k, stride=1, groups=8, bias=False):\n",
    "        super().__init__()\n",
    "        assert c_in % groups == c_out % groups == 0, \"c_in and c_out must be divided by groups\"\n",
    "        assert k % 2 == 1, \"k must be odd\"\n",
    "        assert c_out % 2 == 0, \"c_out must be even\"\n",
    "        \n",
    "        padding = k // 2\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        \n",
    "        self.key_conv = nn.Conv2d(c_in, c_out, 1, padding=padding, groups=groups, bias=bias, padding_mode='reflect')\n",
    "        self.query_conv = nn.Conv2d(c_in, c_out, 1, groups=groups, bias=bias)\n",
    "        self.value_conv = nn.Conv2d(c_in, c_out, 1, padding=padding, groups=groups, bias=bias, padding_mode='reflect')\n",
    "        \n",
    "        self.r_ai = nn.Parameter(torch.randn(1, c_out//2, k, 1))\n",
    "        self.r_aj = nn.Parameter(torch.randn(1, c_out//2, 1, k))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        n = self.c_out // self.groups\n",
    "        \n",
    "        q = self.query_conv(x).view(b, self.groups, n, h, w, 1)\n",
    "        k = self.key_conv(x).unfold(2, self.k, self.stride).unfold(3, self.k, self.stride).contiguous().view(b, self.groups, n, h, w, -1)\n",
    "        v = self.value_conv(x).unfold(2, self.k, self.stride).unfold(3, self.k, self.stride).contiguous().view(b, self.groups, n, h, w, -1)\n",
    "        \n",
    "        r = torch.cat((self.r_ai.expand(b, -1, -1, self.k), self.r_aj.expand(b, -1, self.k, -1)), dim=1).view(b, self.groups, n, -1)\n",
    "        r = r[..., None, None, :].expand(-1, -1, -1, h, w, -1)\n",
    "        \n",
    "        y = (torch.softmax((q*(k+r)).sum(2, keepdims=True), dim=-1) * v).sum(-1).view(b, self.c_out, h, w)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Attention block as described in [_Stand-Alone Self-Attention in Vision Models_](https://arxiv.org/pdf/1906.05909.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SASA(nn.Module):\n",
    "    def __init__(self, kernel_size, n_kernels, n_layers, n_groups, n_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stem = ConvBnRelu(3, n_kernels, 7, stride=2, padding=3, padding_mode='reflect')\n",
    "        in_c = n_kernels\n",
    "        out_c = 2*n_kernels\n",
    "        for k in range(n_layers):\n",
    "            self.add_module(f'sasa_block_{k}', SelfAttentionBlock(in_c, out_c, kernel_size, groups=n_groups, padding_mode='reflect'))\n",
    "            self.add_module(f'pool_{k}', nn.AvgPool2d(2, stride=2))\n",
    "            in_c = out_c\n",
    "            out_c *= 2\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat = nn.Flatten(-2, -1)\n",
    "        self.fc = nn.Linear(out_c, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.children():\n",
    "            x = m(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full transformer model as described in [_Stand-Alone Self-Attention in Vision Models_](https://arxiv.org/pdf/1906.05909.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_padding(kernel_size, stride, dilation=1):\n",
    "    padding = ((stride - 1) + dilation * (kernel_size - 1)) // 2\n",
    "    return padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction_channels):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(\n",
    "            channels, reduction_channels, kernel_size=1, padding=0, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(\n",
    "            reduction_channels, channels, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_se = self.avg_pool(x)\n",
    "        x_se = self.fc1(x_se)\n",
    "        x_se = self.relu(x_se)\n",
    "        x_se = self.fc2(x_se)\n",
    "        return x * x_se.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BasicBlock(nn.Module):\n",
    "    __constants__ = ['se', 'downsample']  # for pre 1.4 torchscript compat\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, kernel_size, downsample=None,\n",
    "                 groups=8, base_width=64, use_se=False,\n",
    "                 reduce_first=1, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        assert base_width == 64, 'BasicBlock doest not support changing base width'\n",
    "        first_planes = planes // reduce_first\n",
    "        outplanes = planes * self.expansion\n",
    "\n",
    "        self.sa1 = SelfAttentionBlock(\n",
    "            inplanes, first_planes, kernel_size, groups=groups)\n",
    "        self.bn1 = norm_layer(first_planes)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "        self.sa2 = SelfAttentionBlock(\n",
    "            first_planes, outplanes, kernel_size, groups=groups)\n",
    "        self.bn2 = norm_layer(outplanes)\n",
    "        self.se = SEModule(outplanes, planes // 4) if use_se else None\n",
    "        self.act2 = act_layer(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.sa1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.sa2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.se is not None:\n",
    "            out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.act2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    __constants__ = ['se', 'downsample']  # for pre 1.4 torchscript compat\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, kernel_size, downsample=None,\n",
    "                 groups=8, base_width=64, use_se=False,\n",
    "                 reduce_first=1, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        width = int(math.floor(planes * (base_width / 64)))\n",
    "        first_planes = width // reduce_first\n",
    "        outplanes = planes * self.expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, first_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(first_planes)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "        self.sa = SelfAttentionBlock(\n",
    "            first_planes, width, kernel_size, groups=groups)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.act2 = act_layer(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(width, outplanes, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(outplanes)\n",
    "        self.se = SEModule(outplanes, planes // 4) if use_se else None\n",
    "        self.act3 = act_layer(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act1(out)\n",
    "\n",
    "        out = self.sa(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.act2(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.se is not None:\n",
    "            out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.act3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SANet(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, kernel_size, num_classes=1000, in_chans=3, use_se=False,\n",
    "                 groups=8, base_width=64, stem_width=64, stem_type='',\n",
    "                 block_reduce_first=1, avg_down=False,\n",
    "                 act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, drop_rate=0.0, global_pool='avg',\n",
    "                 zero_init_last_bn=True, block_args=None):\n",
    "        block_args = block_args or dict()\n",
    "        self.num_classes = num_classes\n",
    "        deep_stem = 'deep' in stem_type\n",
    "        self.inplanes = stem_width * 2 if deep_stem else 64\n",
    "        self.groups = groups\n",
    "        self.base_width = base_width\n",
    "        self.drop_rate = drop_rate\n",
    "        self.expansion = block.expansion\n",
    "        self.kernel_size = kernel_size\n",
    "        super().__init__()\n",
    "\n",
    "        # Stem\n",
    "        if deep_stem:\n",
    "            stem_chs_1 = stem_chs_2 = stem_width\n",
    "            if 'tiered' in stem_type:\n",
    "                stem_chs_1 = 3 * (stem_width // 4)\n",
    "                stem_chs_2 = stem_width if 'narrow' in stem_type else 6 * (stem_width // 4)\n",
    "            self.conv1 = nn.Sequential(*[\n",
    "                nn.Conv2d(in_chans, stem_chs_1, 3, stride=2, padding=1, bias=False),\n",
    "                norm_layer(stem_chs_1),\n",
    "                act_layer(inplace=True),\n",
    "                nn.Conv2d(stem_chs_1, stem_chs_2, 3, stride=1, padding=1, bias=False),\n",
    "                norm_layer(stem_chs_2),\n",
    "                act_layer(inplace=True),\n",
    "                nn.Conv2d(stem_chs_2, self.inplanes, 3, stride=1, padding=1, bias=False)])\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_chans, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Feature Blocks\n",
    "        channels = [64, 128, 256, 512]\n",
    "        llargs = list(zip(channels, layers))\n",
    "        lkwargs = dict(\n",
    "            use_se=use_se, reduce_first=block_reduce_first, act_layer=act_layer, norm_layer=norm_layer,\n",
    "            avg_down=avg_down, **block_args)\n",
    "        self.layer1 = self._make_layer(block, *llargs[0], **lkwargs)\n",
    "        self.layer2 = self._make_layer(block, *llargs[1], **lkwargs)\n",
    "        self.layer3 = self._make_layer(block, *llargs[2], **lkwargs)\n",
    "        self.layer4 = self._make_layer(block, *llargs[3], **lkwargs)\n",
    "\n",
    "        # Head (Pooling and Classifier)\n",
    "        self.global_pool = SelectAdaptivePool2d(pool_type=global_pool)\n",
    "        self.num_features = 512 * block.expansion\n",
    "        self.fc = nn.Linear(self.num_features * self.global_pool.feat_mult(), num_classes)\n",
    "\n",
    "        last_bn_name = 'bn3' if 'Bottle' in block.__name__ else 'bn2'\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                if zero_init_last_bn and 'layer' in n and last_bn_name in n:\n",
    "                    # Initialize weight/gamma of last BN in each residual block to zero\n",
    "                    nn.init.constant_(m.weight, 0.)\n",
    "                else:\n",
    "                    nn.init.constant_(m.weight, 1.)\n",
    "                nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, reduce_first=1,\n",
    "                    use_se=False, avg_down=False, **kwargs):\n",
    "        norm_layer = kwargs.get('norm_layer')\n",
    "        downsample = None\n",
    "        down_kernel_size = 1\n",
    "        if self.inplanes != planes * block.expansion:\n",
    "            downsample_padding = _get_padding(down_kernel_size, 1)\n",
    "            downsample_layers = []\n",
    "            if avg_down:\n",
    "                avg_stride = stride if dilation == 1 else 1\n",
    "                downsample_layers = [nn.AvgPool2d(avg_stride, avg_stride, ceil_mode=True, count_include_pad=False)]\n",
    "            downsample_layers += [\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, 1, padding=downsample_padding, bias=False),\n",
    "                norm_layer(planes * block.expansion)]\n",
    "            downsample = nn.Sequential(*downsample_layers)\n",
    "\n",
    "        bkwargs = dict(\n",
    "            groups=self.groups, base_width=self.base_width, reduce_first=reduce_first,\n",
    "            use_se=use_se, **kwargs)\n",
    "        layers = [block(\n",
    "            self.inplanes, planes, self.kernel_size, downsample, **bkwargs)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.inplanes, planes, self.kernel_size, **bkwargs))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.fc\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool='avg'):\n",
    "        self.global_pool = SelectAdaptivePool2d(pool_type=global_pool)\n",
    "        self.num_classes = num_classes\n",
    "        del self.fc\n",
    "        self.fc = nn.Linear(self.num_features * self.global_pool.feat_mult(), num_classes) if num_classes else None\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.global_pool(x).flatten(1)\n",
    "        if self.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification of ResNet where each 3x3 convolution (except for the stem) is replaced by a `SelfAttentionBlock`. ResNet architecure is directly taken from [`pytorch-image-models`](https://github.com/rwightman/pytorch-image-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sanet18(kernel_size, num_classes=2, in_chans=3, **kwargs):\n",
    "    model = SANet(BasicBlock, [2, 2, 2, 2], kernel_size, num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    return model\n",
    "\n",
    "def sanet34(kernel_size, num_classes=2, in_chans=3, **kwargs):\n",
    "    model = SANet(BasicBlock, [3, 4, 6, 3], kernel_size, num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    return model\n",
    "\n",
    "def sanet26(kernel_size, num_classes=2, in_chans=3, **kwargs):\n",
    "    model = SANet(Bottleneck, [2, 2, 2, 2], kernel_size, num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    return model\n",
    "\n",
    "def sanet26d(kernel_size, num_classes=2, in_chans=3, **kwargs):\n",
    "    model = SANet(\n",
    "        Bottleneck, [2, 2, 2, 2], kernel_size, stem_width=32, stem_type='deep', avg_down=True,\n",
    "        num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    return model\n",
    "\n",
    "def sanet50(kernel_size, num_classes=2, in_chans=3, **kwargs):\n",
    "    model = SANet(Bottleneck, [3, 4, 6, 3], kernel_size, num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    return model\n",
    "\n",
    "def sanet50d(kernel_size, num_classes=2, in_chans=3, **kwargs):\n",
    "    model = SANet(\n",
    "        Bottleneck, [3, 4, 6, 3], kernel_size, stem_width=32, stem_type='deep', avg_down=True,\n",
    "        num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DynamicUnet(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_name, n_classes=2, input_shape=(3, 224, 224), pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if 'cbr' in encoder_name:\n",
    "            args = map(int, encoder_name.split('_')[1:])\n",
    "            encoder = CBR(*args)\n",
    "            cut = -3\n",
    "        elif 'sasa' in encoder_name:\n",
    "            args = map(int, encoder_name.split('_')[1:])\n",
    "            encoder = SASA(*args)\n",
    "            cut = -3\n",
    "        elif 'sanet' in encoder_name:\n",
    "            splits = encoder_name.split('_') \n",
    "            kernel_size = int(splits[-1])\n",
    "            encoder = globals()[splits[0]](kernel_size)\n",
    "            cut = -2\n",
    "        else:\n",
    "            encoder = timm.create_model(encoder_name, pretrained=pretrained)\n",
    "            cut = -2\n",
    "\n",
    "        self.encoder = nn.Sequential(*(list(encoder.children())[:cut]+[nn.ReLU()]))\n",
    "        encoder_sizes, idxs = self._register_output_hooks(input_shape=input_shape)\n",
    "        n_chans = encoder_sizes[-1][1]\n",
    "        middle_conv = nn.Sequential(ConvBnRelu(n_chans, n_chans//2, 3),\n",
    "                                    ConvBnRelu(n_chans//2, n_chans, 3))\n",
    "        decoder = [middle_conv]\n",
    "        for k, (idx, hook) in enumerate(zip(idxs[::-1], self.hooks)):\n",
    "            skip_chans = encoder_sizes[idx][1]\n",
    "            final_div = (k != len(idxs)-1)\n",
    "            decoder.append(DecoderBlock(n_chans, skip_chans, hook, final_div=final_div))\n",
    "            n_chans = n_chans//2 + skip_chans\n",
    "            n_chans = n_chans if not final_div else skip_chans\n",
    "        self.decoder = nn.Sequential(*decoder, PixelShuffleICNR(n_chans, n_chans))\n",
    "        n_chans += input_shape[0]\n",
    "        self.head = nn.Sequential(LastCross(n_chans), nn.Conv2d(n_chans, n_classes, 1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.encoder(x)\n",
    "        y = self.decoder(y)\n",
    "        if y.shape[-2:] != x.shape[-2:]:\n",
    "            y = interpolate(y, x.shape[-2:], mode='nearest')\n",
    "        y = torch.cat([x, y], dim=1)\n",
    "        y = self.head(y)\n",
    "        return y\n",
    "    \n",
    "        \n",
    "    def _register_output_hooks(self, input_shape=(3, 224, 224)):\n",
    "        sizes, modules = get_sizes(self.encoder, input_shape=input_shape)\n",
    "        mods = []\n",
    "        idxs = np.where(sizes[:-1, -1] != sizes[1:, -1])[0]\n",
    "        def _hook(model, input, output):\n",
    "            return output\n",
    "                \n",
    "        for k in idxs[::-1]:\n",
    "            out_shape = sizes[k]\n",
    "            m = modules[k]\n",
    "            if 'downsample' not in m.name:\n",
    "                mods.append(m)\n",
    "        self.hooks = Hooks(mods, _hook)\n",
    "        \n",
    "        return sizes, idxs\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, \"hooks\"): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet created using encoder from `encoder_name`. Encoder can be anything coded in [`timm`](https://github.com/rwightman/pytorch-image-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted .~21_models.modules.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
