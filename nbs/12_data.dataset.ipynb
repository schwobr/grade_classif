{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "> Classes used to create `pytorch` compatible datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from grade_classif.data.loaders import ImageLoader, MaskLoader, CategoryLoader\n",
    "from grade_classif.data.utils import show_img, np_to_tensor\n",
    "from grade_classif.data.read import get_items\n",
    "from grade_classif.core import ifnone\n",
    "import pandas as pd\n",
    "from albumentations import Compose\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, items, labels, item_loader, label_loader):\n",
    "        super().__init__()\n",
    "        self.items = items\n",
    "        self.labels = labels\n",
    "        self.item_loader = item_loader\n",
    "        self.label_loader = label_loader\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        item, label = self.items[i], self.labels[i]\n",
    "        x = self.item_loader(item)\n",
    "        y = self.label_loader(label)\n",
    "        return x, y\n",
    "    \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, label_func, item_loader, label_loader, after_open=None, recurse=True, extensions=None, include=None, exclude=None):\n",
    "        folder = Path(folder)\n",
    "        items, labels = get_items(folder, label_func, recurse=recurse, extensions=extensions, include=include, exclude=exclude)\n",
    "        return cls(items, labels, item_loader, label_loader, after_open=after_open)\n",
    "    \n",
    "    def to_tensor(self, tfms=None, tfm_y=True):\n",
    "        return TensorDataset(self, tfms=tfms, tfm_y=tfm_y)\n",
    "    \n",
    "    def split_by_list(self, train, valid, test=None):\n",
    "        return SplitDataset(self.__class__(train[0], train[1], self.item_loader, self.label_loader),\n",
    "                            self.__class__(valid[0], valid[1], self.item_loader, self.label_loader),\n",
    "                            None if test is None else self.__class__(test[0], test[1], self.item_loader, self.label_loader))\n",
    "    \n",
    "    def split_by_folder(self):\n",
    "        train = ([], [])\n",
    "        valid = ([], [])\n",
    "        test = ([], [])\n",
    "        for item, label in zip(self.items, self.labels):\n",
    "            if 'train' in item.parts:\n",
    "                train[0].append(item)\n",
    "                train[1].append(label)\n",
    "            elif 'valid' in item.parts:\n",
    "                valid[0].append(item)\n",
    "                valid[1].append(label)\n",
    "            elif 'test' in item.parts:\n",
    "                test[0].append(item)\n",
    "                test[1].append(label)\n",
    "        if test[0] == []:\n",
    "            test = None\n",
    "        return self.split_by_list(train, valid, test)\n",
    "    \n",
    "    def split_by_csv(self, csv, column='split'):\n",
    "        df = pd.read_csv(csv, header='infer')\n",
    "        train = ([], [])\n",
    "        valid = ([], [])\n",
    "        test = ([], [])\n",
    "        train_ids = df.loc[df[column] == 'train', 'scan']\n",
    "        valid_ids = df.loc[df[column] == 'valid', 'scan']\n",
    "        test_ids = df.loc[df[column] == 'test', 'scan']\n",
    "        for item, label in zip(self.items, self.labels):\n",
    "            scan_name = item.parent.name\n",
    "            if scan_name in train_ids.values:\n",
    "                train[0].append(item)\n",
    "                train[1].append(label) \n",
    "            elif scan_name in valid_ids.values:\n",
    "                valid[0].append(item)\n",
    "                valid[1].append(label)\n",
    "            elif scan_name in test_ids.values:\n",
    "                test[0].append(item)\n",
    "                test[1].append(label)\n",
    "        if test[0] == []:\n",
    "            test = None\n",
    "        return self.split_by_list(train, valid, test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class for all datasets. It is constructed using list of `items` and `labels`, most of the time as `Path` or `str` objects, with corresponding `item_loader` and `label_loader` as `ItemLoader` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ClassDataset(MyDataset):\n",
    "    def __init__(self, *args, n_classes=2, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n_classes = n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageClassifDataset(ClassDataset):\n",
    "    def show(self, k, ax=None, figsize=(3,3), hide_axis=True, cmap='viridis', **kwargs):\n",
    "        x, y  = self[k]\n",
    "        y = self.label_loader.classes[y]\n",
    "        ax = show_img(x, ax=ax, hide_axis=hide_axis, cmap=cmap, figsize=figsize, title=str(y), **kwargs)\n",
    "        \n",
    "    def show_rand(self, ax=None, figsize=(3,3), hide_axis=True, cmap='viridis', **kwargs):\n",
    "        k = random.randint(0, len(self)-1)\n",
    "        self.show(k, ax=ax, figsize=figsize, hide_axis=hide_axis, cmap=cmap, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, label_func, n_classes=None, classes=None, recurse=True, extensions=None, include=None, exclude=None, **kwargs):\n",
    "        folder = Path(folder)\n",
    "        items, labels = get_items(folder, label_func, recurse=recurse, extensions=extensions, include=include, exclude=exclude)\n",
    "        return cls(items, labels, ImageLoader(**kwargs), CategoryLoader(n_classes, classes), n_classes=ifnone(n_classes, len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageSegmentDataset(ClassDataset):\n",
    "    def show(self, k, ax=None, figsize=(3,3), title=None, hide_axis=True, cmap='tab20', **kwargs):\n",
    "        x, y  = self[k]\n",
    "        ax = show_img(x, ax=ax, hide_axis=hide_axis, cmap=cmap, figsize=figsize, **kwargs)\n",
    "        ax = show_img(y, ax=ax, hide_axis=hide_axis, cmap=cmap, figsize=figsize,\n",
    "                        interpolation='nearest', alpha=alpha, vmin=0, title=title, **kwargs)\n",
    "\n",
    "    def show_rand(self, ax=None, figsize=(3,3), hide_axis=True, cmap='tab20', **kwargs):\n",
    "        k = random.randint(0, len(self)-1)\n",
    "        self.show(k, ax=ax, figsize=figsize, hide_axis=hide_axis, cmap=cmap, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, label_func, n_classes=None, classes=None, recurse=True, extensions=None, include=None, exclude=None):\n",
    "        folder = Path(folder)\n",
    "        items, labels = get_items(folder, label_func, recurse=recurse, extensions=extensions, include=include, exclude=exclude)\n",
    "        return cls(items, labels, ImageLoader(), MaskLoader(), n_classes=ifnone(n_classes, len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NormDataset(MyDataset):\n",
    "    def show(self, k, axs=None, figsize=(3,3), title=None, hide_axis=True, cmap='viridis', **kwargs):\n",
    "        x, y  = self[k]\n",
    "        axs = ifnone(axs, plt.subplots(1, 2, figsize=figsize)[1])\n",
    "        ax = show_img(x, ax=axs[0], hide_axis=hide_axis, cmap=cmap, figsize=figsize, **kwargs)\n",
    "        ax = show_img(y, ax=axs[1], hide_axis=hide_axis, cmap=cmap, figsize=figsize, **kwargs)\n",
    "\n",
    "    def show_rand(self, axs=None, figsize=(3,3), hide_axis=True, cmap='viridis', **kwargs):\n",
    "        k = random.randint(0, len(self)-1)\n",
    "        self.show(k, axs=axs, figsize=figsize, hide_axis=hide_axis, cmap=cmap, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, label_func, csv, recurse=True, extensions=None, include=None, exclude=None):\n",
    "        df = pd.read_csv(csv)\n",
    "        vals = df.loc[df['category'] == 1, 'imageId'].values\n",
    "        def filt(fn):\n",
    "            return fn.parent.stem in vals      \n",
    "        folder = Path(folder)\n",
    "        items, labels = get_items(folder, label_func, recurse=recurse, extensions=extensions, include=include, exclude=exclude, filterfunc=filt)\n",
    "        return cls(items, labels, ImageLoader(open_mode='3G'), ImageLoader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class SplitDataset:\n",
    "    train: Dataset\n",
    "    valid: Dataset\n",
    "    test: Dataset = None\n",
    "        \n",
    "    def to_tensor(self, tfms=None, tfm_y=True, test_tfms=None):\n",
    "        tfms = ifnone(tfms, (None, None))\n",
    "        self.train = self.train.to_tensor(tfms=tfms[0], tfm_y=tfm_y)\n",
    "        self.valid = self.valid.to_tensor(tfms=tfms[1], tfm_y=tfm_y)\n",
    "        if self.test is not None:\n",
    "            self.test = self.test.to_tensor(tfms=test_tfms, tfm_y=tfm_y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, ds, tfms=None, tfm_y=True):\n",
    "        self._ds = ds\n",
    "        self.tfms = ifnone(tfms, [])\n",
    "        self.tfm_y = tfm_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x, y = self._ds[i]\n",
    "        if self.tfms != []:\n",
    "            aug = Compose(self.tfms)\n",
    "            augmented = aug(image=x, mask=y if self.tfm_y else None)\n",
    "            x = augmented['image']\n",
    "            if self.tfm_y: \n",
    "                y = augmented['mask']\n",
    "        x = np_to_tensor(x, type(self._ds.item_loader).__name__.lower().replace('loader', ''))\n",
    "        y = np_to_tensor(y, type(self._ds.label_loader).__name__.lower().replace('loader', ''))\n",
    "        return x, y\n",
    "    \n",
    "    def show(self, k, **kwargs):\n",
    "        self._ds.show(k, **kwargs)\n",
    "        \n",
    "    def show_rand(self, **kwargs):\n",
    "        self._ds.show_rand(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
