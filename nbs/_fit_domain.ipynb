{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tfit_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grade_classif.imports import *\n",
    "from grade_classif.data.read import get_items\n",
    "from grade_classif.models.plmodules import Normalizer\n",
    "from math import ceil\n",
    "import numpy\n",
    "import pickle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.applications.xception as xce\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from slideminer.description import networks\n",
    "from keras.layers import Lambda, Dropout\n",
    "from keras.constraints import unit_norm\n",
    "from keras.callbacks import Callback\n",
    "from itertools import combinations\n",
    "from slideminer.data.datagen import SingleClassBatchGeneratorFromFolder\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from fastai.data.transforms import get_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### #\n",
    "# FUNCTIONS AND CLASSES\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "def create_monitor(datafolder, batch_size, steps, info_dir, every_n=100):\n",
    "    \"\"\"\n",
    "    Create a tf.keras callback class to monitor cosine similarity.\n",
    "\n",
    "    ***********************************************************\n",
    "    \"\"\"\n",
    "    class Monitor(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.info_dir = info_dir\n",
    "            self.datafolder = datafolder\n",
    "            self.steps = steps\n",
    "            self.batch_size = batch_size\n",
    "            self.inter_cosine_dist = []\n",
    "            self.intra_cosine_dist = []\n",
    "            self.every_n = every_n\n",
    "            self.classfolders = {}\n",
    "            self.imlists = {}\n",
    "            for name in os.listdir(self.datafolder):\n",
    "                classdir = os.path.join(self.datafolder, name)\n",
    "                if os.path.isdir(classdir):\n",
    "                    self.classfolders[name] = classdir\n",
    "                    imlist = []\n",
    "                    for imname in os.listdir(classdir):\n",
    "                        if imname.endswith(\".png\"):\n",
    "                            filename = os.path.join(classdir, imname)\n",
    "                            imlist.append(filename)\n",
    "                    self.imlists[name] = imlist\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            if batch % self.every_n == 0:\n",
    "                # create a new model from the global one\n",
    "                eval_model = tf.keras.Model(inputs=self.model.input,\n",
    "                                            outputs=self.model.get_layer(\"features\").output)\n",
    "                cosine_inter = {}\n",
    "                cosine_intra = {}\n",
    "                centroids = {}\n",
    "                for classname, classfolder in self.classfolders.items():\n",
    "                    gen = SingleClassBatchGeneratorFromFolder(self.imlists[classname], self.batch_size)\n",
    "                    print(\"Evaluation of class: {}\".format(classname))\n",
    "                    preds = eval_model.predict(gen, steps=self.steps)\n",
    "                    n = numpy.linalg.norm(preds, axis=1)\n",
    "                    preds /= n[:, numpy.newaxis]\n",
    "                    # compute cosine intra\n",
    "                    centroids[classname] = numpy.mean(preds, axis=0)\n",
    "                    meanpreds = numpy.stack([centroids[classname] for k in range(len(preds))])\n",
    "                    # cosine dist to centroid\n",
    "                    dotprod = (preds * meanpreds).sum(axis=1)\n",
    "                    cosine_intra[classname] = (1. - dotprod).mean(axis=0)\n",
    "\n",
    "                for classid1, classid2 in combinations(self.classfolders.keys(), 2):\n",
    "                    if classid1 < classid2:\n",
    "                        k = \"{}-{}\".format(classid1,\n",
    "                                           classid2)\n",
    "                    else:\n",
    "                        k = \"{}-{}\".format(classid2,\n",
    "                                           classid1)\n",
    "                    # print(\"Evaluation of tuple {}\".format(k))\n",
    "                    # compute cosine dist\n",
    "                    # dot prod of 2 unit vectors\n",
    "                    # perfect similarity is 1.\n",
    "                    dotprod = (centroids[classid1] * centroids[classid2]).sum()\n",
    "                    # I want distance, not similarity, so 1 - dotprod\n",
    "                    cosine_inter[k] = (1. - dotprod)\n",
    "                self.inter_cosine_dist.append(cosine_inter)\n",
    "                self.intra_cosine_dist.append(cosine_intra)\n",
    "\n",
    "        def on_train_end(self, logs={}):\n",
    "            with open(os.path.join(self.info_dir, \"inter_cosine.p\"), \"wb\") as f:\n",
    "                pickle.dump(self.inter_cosine_dist, f)\n",
    "            with open(os.path.join(self.info_dir, \"intra_cosine.p\"), \"wb\") as f:\n",
    "                pickle.dump(self.intra_cosine_dist, f)\n",
    "\n",
    "    return Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, files, labels=None):\n",
    "        super().__init__()\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        f = self.files[idx]\n",
    "        img = imread(str(f)).transpose(2, 0, 1)\n",
    "        img = torch.tensor(img, dtype=torch.float)\n",
    "        if self.labels is None:\n",
    "            return img\n",
    "        else:\n",
    "            return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(norm, x):\n",
    "    x = x.to(norm.main_device)\n",
    "    x /= 255\n",
    "    x = norm.predict(x).detach().clamp(0, 1).cpu().numpy()\n",
    "    return x.transpose(0, 2, 3, 1) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files, datalim, norm=None, probas=None, batchsize=64):\n",
    "    \"\"\"\n",
    "    Load image data.\n",
    "\n",
    "    Given a folder and a max file number.\n",
    "    \"\"\"\n",
    "    # first, get all filenames\n",
    "    \n",
    "    # shuffle the dataset\n",
    "    data = []\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Loading data:\")\n",
    "    print(\"-\" * 20)\n",
    "    ds = MyDataset(files)\n",
    "    sampler = WeightedRandomSampler(probas, datalim, replacement=False)\n",
    "    dl = DataLoader(ds, batch_size=batchsize, num_workers=4, pin_memory=True, sampler=sampler)\n",
    "    for x in tqdm(dl, total=len(dl)):\n",
    "        x = _normalize(norm, x)\n",
    "        data.append(x)\n",
    "    torch.cuda.empty_cache()\n",
    "    return xce.preprocess_input(numpy.concatenate(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_data(files, norm=None, batchsize=64):\n",
    "    \"\"\"\n",
    "    Load image data.\n",
    "\n",
    "    Given a folder and a max file number.\n",
    "    \"\"\"\n",
    "    # first, get all filenames\n",
    "    \n",
    "    # shuffle the dataset\n",
    "    ds = MyDataset(files)\n",
    "    dl = DataLoader(ds, batch_size=batchsize, num_workers=4, pin_memory=True, shuffle=False, timeout=120)\n",
    "    for x in tqdm(dl, total=len(dl)):\n",
    "        x = _normalize(norm, x)\n",
    "        yield xce.preprocess_input(x)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data_generator(files, labels, norm=None, batchsize=64, epochs=20):\n",
    "    ds = MyDataset(files, labels)\n",
    "    dl = DataLoader(ds, shuffle=True, batch_size=batchsize, num_workers=4, pin_memory=True, timeout=120)\n",
    "    for _ in range(epochs):\n",
    "        for x, y in dl:\n",
    "            x = _normalize(norm, x)\n",
    "            yield xce.preprocess_input(x), y.numpy()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(outdirectory, iteration):\n",
    "    \"\"\"\n",
    "    Re-load a previously fine-tuned model.\n",
    "\n",
    "    Given an iteration number (iteration to re-load).\n",
    "    \"\"\"\n",
    "    # load json and create model\n",
    "    with open(os.path.join(outdirectory, 'model/xception.json'), 'r') as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(os.path.join(outdirectory, \"weights/iter_{}.h5\".format(iteration)))\n",
    "    print(\"Loaded model from disk\")\n",
    "    # compilation is useless if model is loaded for prediction only\n",
    "    # loaded_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=loss)\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def save_model(model, weightdirectory, iteration):\n",
    "    \"\"\"\n",
    "    Save the weights of the model in a h5 file.\n",
    "\n",
    "    Given a model and its iteration number, save the model.\n",
    "    \"\"\"\n",
    "    model.save_weights(os.path.join(weightdirectory, \"iter_{}.h5\".format(iteration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_cycle(size):\n",
    "    \"\"\"\n",
    "    Define a color circle for the tsne plot of the classes.\n",
    "\n",
    "    *******************************************************\n",
    "    \"\"\"\n",
    "    cycle = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'gray', 'orange', 'purple']\n",
    "    colors = []\n",
    "    for k in range(size):\n",
    "        colors.append(cycle[k % len(cycle)])\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_from_generator(datagen, generator):\n",
    "    for batch_x, batch_y in generator:\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            x = batch_x[i]\n",
    "            params = datagen.get_random_transform(x.shape)\n",
    "            x = datagen.apply_transform(x, params)\n",
    "            x = datagen.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        yield batch_x, batch_y\n",
    "ImageDataGenerator.flow_from_generator = flow_from_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adaption(datafolder,\n",
    "                    outdir,\n",
    "                    device,\n",
    "                    imsize,\n",
    "                    norm,\n",
    "                    epochs=20,\n",
    "                    iterations=5,\n",
    "                    n_clusters=10,\n",
    "                    threshold=0.75,\n",
    "                    datalim=25000,\n",
    "                    batchsize=16,\n",
    "                    metric_learning=True):\n",
    "    \"\"\"\n",
    "    Adapt a neural network to a new kind of images.\n",
    "\n",
    "    Usually a network previously trained on imagenet.\n",
    "    See tf.keras applications.\n",
    "    \"\"\"\n",
    "    #os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = device\n",
    "\n",
    "    model_dir = os.path.join(outdir, 'model')\n",
    "    weights_dir = os.path.join(outdir, 'weights')\n",
    "    info_dir = os.path.join(outdir, 'info')\n",
    "\n",
    "    datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                 samplewise_center=False,\n",
    "                                 featurewise_std_normalization=False,\n",
    "                                 samplewise_std_normalization=False,\n",
    "                                 zca_whitening=False,\n",
    "                                 rotation_range=20,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.,\n",
    "                                 zoom_range=0.,\n",
    "                                 channel_shift_range=0.,\n",
    "                                 fill_mode='nearest',\n",
    "                                 cval=0.,\n",
    "                                 horizontal_flip=False,\n",
    "                                 vertical_flip=False,\n",
    "                                 rescale=None,\n",
    "                                 data_format=K.image_data_format())\n",
    "\n",
    "    # create directories\n",
    "    ###############################\n",
    "    if os.path.exists(outdir):\n",
    "        # Be careful, this erase all previous work in this directory\n",
    "        shutil.rmtree(outdir)\n",
    "    os.makedirs(outdir)\n",
    "    os.makedirs(model_dir)\n",
    "    os.makedirs(weights_dir)\n",
    "    os.makedirs(info_dir)\n",
    "    ##################################################\n",
    "\n",
    "    # GPU for similarity matrix computation\n",
    "    ###################################################\n",
    "    def similarity(center_t, other_t):\n",
    "        center_t_norm = tf.nn.l2_normalize(center_t, axis=1)\n",
    "        other_t_norm = tf.nn.l2_normalize(other_t, axis=1)\n",
    "        return tf.matmul(center_t_norm, other_t_norm,\n",
    "                         transpose_a=False, transpose_b=True)\n",
    "    ###########################################################\n",
    "\n",
    "    # Gather images in a numpy array\n",
    "    ########################################################\n",
    "    classes = ['04', '05', '08']\n",
    "    def _label_func(x):\n",
    "        for c in classes:\n",
    "            if f'PACS{c}' in x.name:\n",
    "                return c\n",
    "    files = get_files(datafolder, extensions=['.png'])\n",
    "    labels = files.map(_label_func)\n",
    "    labels = numpy.array(labels)\n",
    "    class_probas = numpy.array([1/(labels == c).sum() for c in classes])\n",
    "    probas = np.zeros(len(labels))\n",
    "    for c in classes:\n",
    "        probas[labels==c] = class_probas[classes.index(c)]\n",
    "    probas /= probas.sum()\n",
    "    ########################################################\n",
    "\n",
    "    # Before we start, we instantiate and store xception pre-trained model\n",
    "    ############################################\n",
    "    base_model = xce.Xception(include_top=False,\n",
    "                              weights='imagenet',\n",
    "                              input_shape=(imsize, imsize, 3),\n",
    "                              pooling='avg')\n",
    "    json_string = base_model.to_json()\n",
    "    with open(os.path.join(model_dir, 'xception.json'), \"w\") as text_file:\n",
    "        text_file.write(json_string)\n",
    "    save_model(base_model, weights_dir, 0)\n",
    "    ##############\n",
    "\n",
    "    # create a tensorflow session before we start\n",
    "\n",
    "    # Main Loop\n",
    "    ###################################\n",
    "    for checkpoint in range(1, iterations + 1):\n",
    "        K.clear_session()\n",
    "\n",
    "        # extract features\n",
    "        print(\"-\" * 20)\n",
    "        print(\"predicting features:\")\n",
    "        print(\"-\" * 20)\n",
    "        sample_idxs = numpy.random.choice(numpy.arange(len(files)), datalim, False, probas)\n",
    "        epoch_files = files[sample_idxs]\n",
    "        features = base_model.predict(yield_data(epoch_files, norm=norm, batchsize=batchsize))\n",
    "        features = numpy.array(features)\n",
    "        \n",
    "        K.clear_session()\n",
    "        del base_model\n",
    "\n",
    "        # instance of k-means\n",
    "        print(\"-\" * 20)\n",
    "        print(\"fitting k-means:\")\n",
    "        print(\"-\" * 20)\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        distances = kmeans.fit_transform(features)\n",
    "\n",
    "        # select best candidates for k-means centers in the dataset\n",
    "        center_idx = numpy.argmin(distances, axis=0)\n",
    "        centers = numpy.array([features[i] for i in center_idx])\n",
    "\n",
    "        # compute similarity matrix\n",
    "        print(\"-\" * 20)\n",
    "        print(\"similarity matrix:\")\n",
    "        similarities = similarity(centers, features).numpy()\n",
    "        print(\"similarity has shape: \", similarities.shape)\n",
    "        print(\"similarity: \", similarities)\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        # select images closest to centers\n",
    "        print(\"-\" * 20)\n",
    "        print(\"reliability selection:\")\n",
    "        print(\"-\" * 20)\n",
    "        reliable_image_idx = numpy.unique(numpy.argwhere(similarities > threshold)[:, 1])\n",
    "        print(\"checkpoint {}: # reliable images {}\".format(checkpoint, len(reliable_image_idx)))\n",
    "        sys.stdout.flush()\n",
    "        int_labels = numpy.array([kmeans.labels_[i] for i in reliable_image_idx])\n",
    "        labels = to_categorical(int_labels)            \n",
    "\n",
    "        # write a tsne visualization figure, to check if visualization improves\n",
    "        print(\"-\" * 20)\n",
    "        print(\"TSNE figure:\")\n",
    "        tsne = TSNE(n_components=2)\n",
    "        x2d = tsne.fit_transform(numpy.array([features[i] for i in reliable_image_idx]))\n",
    "        print(\"TSNE shape: \", x2d.shape)\n",
    "        print(\"TSNE: \", x2d)\n",
    "        print(\"-\" * 20)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        colors = color_cycle(n_clusters)\n",
    "        for i, c, label in zip(list(range(n_clusters)), colors, [str(id) for id in range(n_clusters)]):\n",
    "            print(\"current_label: \", i)\n",
    "            print(\"shape of kmeans predictions: \", int_labels.shape)\n",
    "            print(\"kmeans predictions: \", int_labels)\n",
    "            print(\"points in masked predictions: \", (int_labels == i).sum())\n",
    "            plt.scatter(x2d[int_labels == i, 0], x2d[int_labels == i, 1], c=c, label=label)\n",
    "        plt.legend()\n",
    "        plt.title(\"TSNE visualization, based on {} reliable images\".format(len(reliable_image_idx)))\n",
    "        plt.savefig(os.path.join(info_dir, \"tsne_iter_{}.png\".format(checkpoint - 1)))\n",
    "        \n",
    "        # Fine tune\n",
    "        print(\"-\" * 20)\n",
    "        print(\"Fine tuning:\")\n",
    "        print(\"-\" * 20)\n",
    "        base_model = xce.Xception(include_top=False,\n",
    "                                  weights='imagenet',\n",
    "                                  input_shape=(imsize, imsize, 3),\n",
    "                                  pooling='avg')\n",
    "\n",
    "        # compute head of the classifier, for cosine learning\n",
    "        renamer = Lambda(lambda t: t, name=\"features\")\n",
    "        regularizer = Dropout(0.8)\n",
    "        if metric_learning:\n",
    "            normalizer = Lambda(lambda t: K.l2_normalize(1000 * t, axis=-1))\n",
    "            classifier = networks.CosineDense(n_clusters,\n",
    "                                              use_bias=False,\n",
    "                                              kernel_constraint=unit_norm(),\n",
    "                                              activation=\"softmax\")\n",
    "            y = renamer(base_model.output)\n",
    "            y = normalizer(y)\n",
    "            y = regularizer(y)\n",
    "            y = classifier(y)\n",
    "        else:\n",
    "            classifier = tf.keras.layers.Dense(n_clusters, activation=\"softmax\")\n",
    "            y = renamer(base_model.output)\n",
    "            y = regularizer(y)\n",
    "            y = classifier(y)\n",
    "\n",
    "        model = tf.keras.Model(inputs=base_model.input, outputs=y)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=4)\n",
    "        sched = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=1, factor=0.2, min_delta=0.1, min_lr=1e-5)\n",
    "        model.compile(optimizer=Adam(lr=0.01), loss=\"categorical_crossentropy\")\n",
    "        gen = fit_data_generator(epoch_files[reliable_image_idx], labels, norm=norm, batchsize=batchsize, epochs=epochs)\n",
    "        model.fit(datagen.flow_from_generator(gen), steps_per_epoch=ceil(len(reliable_image_idx)/batchsize), epochs=epochs, callbacks=[callback, sched])\n",
    "        save_model(base_model, weights_dir, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grade_classif.params.parser import hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.open_mode = 'H'\n",
    "hparams.transforms = 1\n",
    "hparams.normalizer = 'cbr_5_32_4'\n",
    "#hparams.loss = 'mse'\n",
    "hparams.size = 299\n",
    "hparams.gpus = [1]\n",
    "hparams.filt = 'all'\n",
    "hparams.batch_size = 64\n",
    "hparams.patch_classes = None\n",
    "hparams.norm_csv = None\n",
    "hparams.concept_classes = None\n",
    "hparams.level = 1\n",
    "hparams.loss = 'mse'\n",
    "# hparams.train_percent = 0.01\n",
    "hparams.data = Path('/data/DeepLearning/SCHWOB_Robin/Patches_299/Patches_299_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalizer(hparams)\n",
    "\n",
    "norm.load('6cacb7558df8464a843775ca6694ed3b')\n",
    "\n",
    "norm.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:1'):\n",
    "    domain_adaption(str(hparams.data), '/data/DeepLearning/SCHWOB_Robin/xception_weights', '1', 299, norm, epochs=30, iterations=20, batchsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/data/DeepLearning/SCHWOB_Robin/xception_weights', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = '/data/DeepLearning/SCHWOB_Robin/Patches_299/Patches_299_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['04', '05', '08']\n",
    "def _label_func(x):\n",
    "    for c in classes:\n",
    "        if f'PACS{c}' in x.name:\n",
    "            return c\n",
    "files = get_files(datafolder, extensions=['.png'])\n",
    "labels = files.map(_label_func)\n",
    "labels = numpy.array(labels)\n",
    "class_probas = numpy.array([1/(labels == c).sum() for c in classes])\n",
    "probas = np.zeros(len(labels))\n",
    "for c in classes:\n",
    "    probas[labels==c] = class_probas[classes.index(c)]\n",
    "probas /= probas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d016d13218489e91488a56c7305c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1563.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = model.predict(yield_data(files, 25000, norm=norm, probas=probas, batchsize=16))\n",
    "features = numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10)\n",
    "distances = kmeans.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_idx = numpy.argmin(distances, axis=0)\n",
    "centers = numpy.array([features[i] for i in center_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
