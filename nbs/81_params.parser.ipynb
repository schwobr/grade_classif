{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp params.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.params.defaults import *\n",
    "import os\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--oversample'], dest='oversample', nargs=0, const=True, default=False, type=None, choices=None, help='specify to enable oversampling instead of weighting loss', metavar=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "_parser = ArgumentParser()\n",
    "_parser.add_argument('--file', '-f', help='notebook convenience')\n",
    "_parser.add_argument('--HistoryManager.hist_file', help='nbconvert convenience')\n",
    "_parser.add_argument('--sched', default=SCHED, choices=['one-cycle', 'cosine-anneal', 'reduce-on-plateau', 'none'], help='scheduler for the optimizer')\n",
    "_parser.add_argument('--datafolder', default=DATA, help='path to folder containing data')\n",
    "_parser.add_argument('--data-csv', default=DATA_CSV, help='path to csv listing scans with their grades and split')\n",
    "_parser.add_argument('--patch-classes', default=PATCH_CLASSES, help='path to csv giving a class for each patch.')\n",
    "_parser.add_argument('--level', default=LEVEL, type=int, help='zoom level to work on')\n",
    "_parser.add_argument('--resume-version', default=RESUME, help='version of model to load before training')\n",
    "_parser.add_argument('--resume-checkpoint', default=None, help='checkpoint to load from when resuming.')\n",
    "_parser.add_argument('--batch-size', default=BATCH_SIZE, type=int, help='batch size')\n",
    "_parser.add_argument('--size', default=SIZE, type=int, help='size of the image (as an integer, image is supposed to be square)')\n",
    "_parser.add_argument('--loss', default=LOSS, choices=['cross-entropy', 'mse', 'focal'], help='loss function')\n",
    "_parser.add_argument('--savedir', default=MODELS, help='directory to save models and logs in')\n",
    "_parser.add_argument('--model', default=MODEL, help='name of the base architecture to use for classification')\n",
    "_parser.add_argument('--normalizer', default=NORMALIZER, help='path to normalizer file as torchscript module')\n",
    "_parser.add_argument('--rand-weights', action='store_true', help='specify to avoid using a pretrained model for training')\n",
    "_parser.add_argument('--gpus', default=GPUS, nargs='*', type=int, help='list of gpus you want to use for training (as numbers)')\n",
    "_parser.add_argument('--reduction', default=REDUCTION, choices=['mean', 'sum', 'none'], help='reduction to apply to loss')\n",
    "_parser.add_argument('--epochs', default=EPOCHS, type=int, help='number of epochs')\n",
    "_parser.add_argument('--weights', type=float, nargs=\"*\", default=None, help='weights for cross-entropy loss.')\n",
    "_parser.add_argument('--dropout', default=DROPOUT, type=float, help='dropout value')\n",
    "_parser.add_argument('--lr', default=LR, type=float, help='learning rate')\n",
    "_parser.add_argument('--wd', type=float, default=WD, help='weight decay')\n",
    "_parser.add_argument('--sample-mode', type=int, default=SAMPLE_MODE, choices=[0, 1, 2], help='type 0 for regular sampling, 1 for oversampling, 2 for undersampling')\n",
    "_parser.add_argument('--transforms', type=int, default=TRANSFORMS, choices=[0, 1, 2, 3, 4, 5], help='0 means no transform, above enables use of function `get_transformX` with X the number entered.')\n",
    "_parser.add_argument('--filt', default=FILT, choices=['K', 'K_inter', 'out', 'all', 'K_all'], help='patches to filter depending on their corresponding concept')\n",
    "_parser.add_argument('--open-mode', default=OPEN_MODE, choices=['3G', 'RGB', 'H', 'E', 'HEG'], help='How the image should be opened (3G for grayscale and RGB for color)')\n",
    "_parser.add_argument('--train-percent', default=TRAIN_PERCENT, type=float, help='Portion of the training set to run fit on.')\n",
    "_parser.add_argument('--topk', default=TOPK, type=int, help='Number of patches per slide to train on for MIL.')\n",
    "_parser.add_argument('--coord-csv', default=COORD_CSV, help='path to csv containing coordinates for each patch to extract from all slides.')\n",
    "_parser.add_argument('--patches-per-slide', type=int, default=10, help='number of patches to select for each slide when using RNN aggregator on MIL.')\n",
    "_parser.add_argument('--rnn-hidden-dims', type=int, default=128, help='size of hidden representation in RNN aggregator.')\n",
    "_parser.add_argument('--profiler', default=None, choices=['simple', 'advanced'], help='type of profiler to use from pytorch_lightning.profiler.')\n",
    "_parser.add_argument('--mixed-precision', action=\"store_true\", help=\"specify to use mixed precision training.\")\n",
    "_parser.add_argument('--forget-rate', type=float, default=0.5, help='maximum part of the training set to drop for co-teaching.')\n",
    "_parser.add_argument('--forget-steps', type=int, default=10, help='number of epochs before getting to maximum forget rate.')\n",
    "_parser.add_argument('--disagree-only', action='store_true', help='specify to only train co-teaching models on data that is disagreed upon.')\n",
    "_parser.add_argument('--max-patches-per-slide', type=int, default=None, help='maximum number of patches from each slide to use for training.')\n",
    "_parser.add_argument('--glimpse-size', type=int, default=256, help='size of glimpse image for RNN attention.')\n",
    "_parser.add_argument('--n-glimpses', type=int, default=3, help='number of glimpses to observe in RNN attention.')\n",
    "_parser.add_argument('--gamma', type=float, default=1, help='gamma parameter for RNN attention.')\n",
    "_parser.add_argument('--auto-lr-find', action='store_true', help='specify to run a lr finder before training.')\n",
    "_parser.add_argument('--pacs-filt', default=None, choices=['4', '5', '8', '45', '48', '58'], help='specify a PACS datasets to use, use all otherwise.')\n",
    "_parser.add_argument('--norm-ref', default='/data/DeepLearning/SCHWOB_Robin/CF_Normacolor_0182_41472_67392.png', help='path to reference image for staintools image normalization methods.')\n",
    "_parser.add_argument('--norm-method', default=None, choices=['reinhard', 'vahadane', 'macenko'], help='staintool normalization method to use.')\n",
    "_parser.add_argument('--num-workers', default=4, type=int, help='number of cpu workers to use for data loading.')\n",
    "_parser.add_argument('--embed-dim', default=2048, type=int, help='size of feature vector for WSITransformer.')\n",
    "_parser.add_argument('--padding-file', default='/data/DeepLearning/SCHWOB_Robin/padding_2048_1024_1.npy', help='path to file containing feature vector to use for padding in WSITransformer.')\n",
    "_parser.add_argument('--deepspeed', action='store_true', help='specify to enable deepspeed plugin. Will also enable mixed precision by default.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "hparams = _parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, hparams.gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 16_data.modules.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
