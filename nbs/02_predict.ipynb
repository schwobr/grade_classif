{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.data.utils import load_batches\n",
    "from grade_classif.models.plmodules import GradesClassifModel\n",
    "from grade_classif.data.read import get_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def predict_one_scan_one_level(model, fn):\n",
    "    preds = []\n",
    "    for x in load_batches(fn, bs=model.bs, device=model.main_device):\n",
    "        preds.append(model.predict(x).detach().cpu()[:, 1])\n",
    "    return sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def predict_one_scan(hparams):\n",
    "    preds = []\n",
    "    for level, version in zip(hparams.levels, hparams.versions):\n",
    "        hparams.level = level\n",
    "        model = GradesClassifModel(hparams)\n",
    "        model.load(version)\n",
    "        path = get_scan(hparams.data/f'{hparams.data.name}_{level}', hparams.scan, include=['train', 'valid'])\n",
    "        preds.append(predict_one_scan_one_level(model, path))\n",
    "    return sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def predict_all(hparams):\n",
    "    df = pd.read_csv(hparams.data_csv, header='infer')\n",
    "    preds = []\n",
    "    for scan in df['scan']:\n",
    "        hparams.scan = scan\n",
    "        preds.append(predict_one_scan(hparams))\n",
    "    return preds, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data_read.ipynb.\n",
      "Converted 11_data_loaders.ipynb.\n",
      "Converted 12_data_dataset.ipynb.\n",
      "Converted 13_data_utils.ipynb.\n",
      "Converted 14_data_transforms.ipynb.\n",
      "Converted 20_models_pl_modules.ipynb.\n",
      "Converted 21_models_modules.ipynb.\n",
      "Converted 22_models_utils.ipynb.\n",
      "Converted 23_models_hooks.ipynb.\n",
      "Converted 80_params_defaults.ipynb.\n",
      "Converted 81_params_norm.ipynb.\n",
      "Converted 82_params_classif.ipynb.\n",
      "Converted 83_params_predict.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
