{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.imports import *\n",
    "from torchmetrics import Metric\n",
    "from kornia.color import rgb_to_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _input_format_classification(\n",
    "    preds: torch.Tensor, target: torch.Tensor, threshold: float = 0.5\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Convert preds and target tensors into label tensors\n",
    "    Args:\n",
    "        preds: either tensor with labels, tensor with probabilities/logits or\n",
    "            multilabel tensor\n",
    "        target: tensor with ground true labels\n",
    "        threshold: float used for thresholding multilabel input\n",
    "    Returns:\n",
    "        preds: tensor with labels\n",
    "        target: tensor with labels\n",
    "    \"\"\"\n",
    "    if not (preds.ndim == target.ndim or preds.ndim == target.ndim + 1):\n",
    "        raise ValueError(\"preds and target must have same number of dimensions, or one additional dimension for preds\")\n",
    "\n",
    "    if preds.ndim == target.ndim + 1:\n",
    "        # multi class probabilites\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "    if preds.ndim == target.ndim and preds.is_floating_point():\n",
    "        # binary or multilabel probablities\n",
    "        preds = (preds >= threshold).long()\n",
    "    return preds, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _reshape(input, target):\n",
    "    n = target.shape[0]\n",
    "    input = torch.softmax(input, dim=1)\n",
    "    input = input.argmax(dim=-1).view(n,-1)\n",
    "    target = target.view(n,-1)\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def accuracy(tp, fp, tn, fn):\n",
    "    return (tp+tn)/(tp+fp+fn+tn+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fp_rate(tp, fp, tn, fn):\n",
    "    return fp/(fp+tn+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fn_rate(tp, fp, tn, fn):\n",
    "    return fn/(fn+tp+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def precision(tp, fp, tn, fn, cat=1):\n",
    "    if cat == 1:\n",
    "        return tp/(fp+tp+1e-7)\n",
    "    else:\n",
    "        return tn/(fn+tn+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def recall(tp, fp, tn, fn, cat=1):\n",
    "    if cat == 1:\n",
    "        return tp/(fn+tp+1e-7)\n",
    "    else:\n",
    "        return tn/(fp+tn+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def f_beta(tp, fp, tn, fn, beta=1, cat=1):\n",
    "    prec = precision(tp, fp, tn, fn, cat)\n",
    "    rec = recall(tp, fp, tn, fn, cat)\n",
    "    return ((1+beta**2)*prec*rec+1e-7)/(beta**2*prec+rec+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def f_1(tp, fp, tn, fn, cat=1):\n",
    "    return f_beta(tp, fp, tn, fn, beta=1, cat=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pcc(mu_x, sigma_x, mu_y, sigma_y, mu_xy):\n",
    "    return (mu_xy-mu_x*mu_y)/(sigma_x*sigma_y+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " numpy>=1.18 torch>=1.7 torchvision>=0.8 pytorch-lightning>=1.2 torchmetrics>=0.2 opencv-python>=4.1 timm>=0.3 tqdm>=4.35 pandas>=1.2 openslide-python>=1.2 staintools>=2.1 fastcore>=1.3 matplotlib>=3.3 scikit-image>=0.17 pillow>=7.2 albumentations>=0.4 kornia>=0.5 scipy>=1.6 \n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(\"\"\"\n",
    "numpy>=1.18\n",
    "torch>=1.7\n",
    "torchvision>=0.8\n",
    "pytorch-lightning>=1.2\n",
    "torchmetrics>=0.2\n",
    "opencv-python>=4.1\n",
    "timm>=0.3\n",
    "tqdm>=4.35\n",
    "pandas>=1.2\n",
    "openslide-python>=1.2\n",
    "staintools>=2.1\n",
    "fastcore>=1.3\n",
    "matplotlib>=3.3\n",
    "scikit-image>=0.17\n",
    "pillow>=7.2\n",
    "albumentations>=0.4\n",
    "kornia>=0.5\n",
    "scipy>=1.6\n",
    "\"\"\".split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ssim(mu_x, sigma_x, mu_y, sigma_y, mu_xy, k1=0.01, k2=0.01):\n",
    "    return (\n",
    "        (2 * mu_x * mu_y + k1)\n",
    "        * (2 * (mu_xy - mu_x * mu_y) + k2)\n",
    "        / ((mu_x ** 2 + mu_y ** 2 + k1) * (sigma_x ** 2 + sigma_y ** 2 + k2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def Accuracy(Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.add_state(\"true\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        \n",
    "    def update(self, preds, target):\n",
    "        preds, target = _input_format_classification(preds, target, self.threshold)\n",
    "        self.true += (preds == target).sum()\n",
    "        self.total += target.numel()\n",
    "    \n",
    "    def compute(self):\n",
    "        return self.true.float() / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ClassifMetrics(Metric):\n",
    "    def __init__(self, n_classes=2, threshold=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"tp\", default=torch.zeros(n_classes), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"tn\", default=torch.zeros(n_classes), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fp\", default=torch.zeros(n_classes), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fn\", default=torch.zeros(n_classes), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds, target):\n",
    "        preds, target = _input_format_classification(preds, target, self.threshold)\n",
    "        for k in range(self.n_classes):\n",
    "            self.tp[k] += ((preds == k) & (target == k)).sum()\n",
    "            self.tn[k] += ((preds != k) & (target != k)).sum()\n",
    "            self.fp[k] += ((preds == k) & (target != k)).sum()\n",
    "            self.fn[k] += ((preds != k) & (target == k)).sum()\n",
    "        self.total += target.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.tp.float() / (self.tp + self.fp)\n",
    "        recall = self.tp.float() / (self.tp + self.fn)\n",
    "        ret = {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": (2 * precision * recall) / (precision + recall),\n",
    "            \"accuracy\": self.tp.sum().float() / self.total\n",
    "        }\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NormMetrics(Metric):\n",
    "    def __init__(self, k1=0.01, k2=0.01, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.add_state(\"mu_x\", default=[], dist_reduce_fx=\"cat\")\n",
    "        self.add_state(\"mu_y\", default=[], dist_reduce_fx=\"cat\")\n",
    "        self.add_state(\"mu_xy\", default=[], dist_reduce_fx=\"cat\")\n",
    "        self.add_state(\"sigma_x\", default=[], dist_reduce_fx=\"cat\")\n",
    "        self.add_state(\"sigma_y\", default=[], dist_reduce_fx=\"cat\")\n",
    "        \n",
    "    def update(self, preds, targets):\n",
    "        y = rgb_to_grayscale(targets.detach()).squeeze(1)\n",
    "        y_hat = rgb_to_grayscale(preds.detach()).squeeze(1)\n",
    "        self.mu_x.append(torch.mean(y, axis=(-2, -1)).float())\n",
    "        self.sigma_x.append(torch.std(y, axis=(-2, -1)).float())\n",
    "        self.mu_y.append(torch.mean(y_hat, axis=(-2, -1)).float())\n",
    "        self.sigma_y.append(torch.std(y_hat, axis=(-2, -1)).float())\n",
    "        self.mu_xy.append(torch.mean(y * y_hat, axis=(-2, -1)).float())\n",
    "    \n",
    "    def compute(self):\n",
    "        mu_x = torch.cat(self.mu_x)\n",
    "        sigma_x = torch.cat(self.sigma_x)\n",
    "        mu_y = torch.cat(self.mu_y)\n",
    "        sigma_y = torch.cat(self.sigma_y)\n",
    "        mu_xy = torch.cat(self.mu_xy)\n",
    "        ret = {}\n",
    "        ret[\"ssim\"] = ssim(mu_x, sigma_x, mu_y, sigma_y, mu_xy).mean()\n",
    "        ret[\"pcc\"] = pcc(mu_x, sigma_x, mu_y, sigma_y, mu_xy).mean()\n",
    "        ret[\"cd\"] = (sigma_y / mu_y - sigma_x / mu_x).mean()\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 16_data.modules.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
