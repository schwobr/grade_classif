{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data \n",
    "> Defines utilities function for reading and manipulating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.core import ifnone\n",
    "from grade_classif.imports import *\n",
    "from fastcore.foundation import L, setify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _check_include(obj: Path, include: Sequence[str]) -> bool:\n",
    "    return include is None or obj.name in include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _check_exclude(obj: Path, exclude: Sequence[str]) -> bool:\n",
    "    return exclude is None or obj.name not in exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _check_valid(obj: Path, include: Sequence[str], exclude: Sequence[str]) -> bool:\n",
    "    return (\n",
    "        _check_include(obj, include)\n",
    "        and _check_exclude(obj, exclude)\n",
    "        and not obj.name.startswith(\".\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [\n",
    "        p / f\n",
    "        for f in fs\n",
    "        if not f.startswith(\".\")\n",
    "        and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)\n",
    "    ]\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):\n",
    "    \"\"\"\n",
    "    Find all files in a folder recursively.\n",
    "    Arguments:\n",
    "        path (str): Path to input folder.\n",
    "        extensions (list of str): list of acceptable file extensions.\n",
    "        recurse (bool): whether to perform a recursive search or not.\n",
    "        folders (list of str): direct subfolders to explore (if None explore all).\n",
    "        followlinks (bool): whether to follow symlinks or not.\n",
    "    Returns:\n",
    "        list: list of all absolute paths to found files.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    folders = L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i, (p, d, f) in enumerate(\n",
    "            os.walk(path, followlinks=followlinks)\n",
    "        ):  # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) != 0 and i == 0:\n",
    "                d[:] = [o for o in d if o in folders]\n",
    "            else:\n",
    "                d[:] = [o for o in d if not o.startswith(\".\")]\n",
    "            if len(folders) != 0 and i == 0 and \".\" not in folders:\n",
    "                continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_leaf_folders(path, folders=None, followlinks=True):\n",
    "    path = Path(path)\n",
    "    folders = L(folders)\n",
    "    res = []\n",
    "    for i, (p, d, f) in enumerate(\n",
    "        os.walk(path, followlinks=followlinks)\n",
    "    ):  # returns (dirpath, dirnames, filenames)\n",
    "        if len(d) == 0 and not p.startswith(\".\"):\n",
    "            res.append(p)\n",
    "            continue\n",
    "        if len(folders) != 0 and i == 0:\n",
    "            d[:] = [o for o in d if o in folders]\n",
    "        else:\n",
    "            d[:] = [o for o in d if not o.startswith(\".\")]\n",
    "        if len(folders) != 0 and i == 0 and \".\" not in folders:\n",
    "            continue\n",
    "    return L(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path.cwd() / \"sample_data/Patches_MGI_256_7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_items(\n",
    "    folder: Union[Path, str],\n",
    "    label_func: Callable[[Path], bool],\n",
    "    recurse: bool = True,\n",
    "    extensions: Optional[Sequence[str]] = None,\n",
    "    include: Optional[Sequence[str]] = None,\n",
    "    exclude: Optional[Sequence[str]] = None,\n",
    "    filterfunc: Optional[Callable[[Path], bool]] = None,\n",
    ") -> Tuple[List[Path], List[Path]]:\n",
    "    items = []\n",
    "    labels = []\n",
    "    folder = Path(folder)\n",
    "    filterfunc = ifnone(filterfunc, lambda x: True)\n",
    "    for obj in folder.iterdir():\n",
    "        if obj.is_file():\n",
    "            if extensions is None or obj.suffix in extensions and filterfunc(obj):\n",
    "                items.append(obj)\n",
    "                labels.append(label_func(obj))\n",
    "        elif recurse and _check_valid(obj, include, exclude):\n",
    "            items_r, labels_r = get_items(\n",
    "                obj, label_func, extensions=extensions, filterfunc=filterfunc\n",
    "            )\n",
    "            items += items_r\n",
    "            labels += labels_r\n",
    "    return items, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads all items and labels in `folder`. Items are stored as `Path` objects. Labels are computed for each item using `label_func`. By default, the search will happen recursively in all subfolders. To disable this behaviour, use `recurse=False`. You can also specify a list of `extensions` to restrict the accepted files, as well as `include` and `exclude` folders (as `str`, these are direct subfolders of `folder`). `filterfunc` can be used to only accept objects for which it returns `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/1/CF_PACS04rescan_07P0201/CF_PACS04rescan_07P0201_32768_98304.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/1/CF_PACS05HE_03026-04H2669/CF_PACS05HE_03026-04H2669_0_131072.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/1/CF_PACS04rescan_07P0208/CF_PACS04rescan_07P0208_32768_98304.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/1/CF_PACS04rescan_06P1306/CF_PACS04rescan_06P1306_0_98304.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/3/CF_PACS04rescan_06P242/CF_PACS04rescan_06P242_0_98304.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/3/CF_PACS05HE_08034-A03.11622B3/CF_PACS05HE_08034-A03.11622B3_32768_65536.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/3/CF_PACS05HE_06003-172.608I/CF_PACS05HE_06003-172.608I_32768_98304.png'),\n",
       "  PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/3/CF_PACS05HE_06003-172.608I/CF_PACS05HE_06003-172.608I_0_98304.png')],\n",
       " ['1', '1', '1', '1', '3', '3', '3', '3'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items, labels = get_items(data, lambda x: x.parts[-3])\n",
    "items[::3], labels[::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_scan(\n",
    "    folder: Union[Path, str],\n",
    "    scan_name: str,\n",
    "    include: Optional[Sequence[str]] = None,\n",
    "    exclude: Optional[Sequence[str]] = None,\n",
    ") -> Path:\n",
    "    dirs = []\n",
    "    folder = Path(folder)\n",
    "    for item in folder.iterdir():\n",
    "        if item.name == scan_name:\n",
    "            return item\n",
    "        if item.is_dir() and _check_valid(item, include, exclude):\n",
    "            dirs.append(item)\n",
    "    for item in dirs:\n",
    "        obj = get_scan(item, scan_name)\n",
    "        if obj is not None:\n",
    "            return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a `Path` object to the folder corresponding to a `scan` name in a specific `folder`. Direct subfolders can be include or excluded using respectively `include` and `exclude`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/DeepLearning/grade_classif/nbs/sample_data/Patches_MGI_256_7/3/CF_PACS05HE_08034-A03.11622B3')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scan(data, \"CF_PACS05HE_08034-A03.11622B3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def split(\n",
    "    scans: Sequence[str], grades: Sequence[str], valid_pct: float = 0.2\n",
    ") -> List[str]:\n",
    "    grades1 = list(filter(lambda x: x == \"1\", grades))\n",
    "    order = np.random.permutation(len(scans))\n",
    "    n = {\"1\": len(grades1), \"3\": len(grades) - len(grades1)}\n",
    "    k = {\"1\": 0, \"3\": 0}\n",
    "    splits = [\"\" for _ in scans]\n",
    "    for o in order:\n",
    "        grade, scan = grades[o], scans[o]\n",
    "        if k[grade] >= valid_pct * n[grade]:\n",
    "            split = \"train\"\n",
    "        else:\n",
    "            split = \"valid\"\n",
    "        k[grade] += 1\n",
    "        splits[o] = split\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a list of scan names `scans`, a list of grades `grades` (both as strings) and ratio for the validation set's size `valid_pct`, randomly splits the dataset between training and validation sets. Returns a list of `'train'` and `'valid'` strings so that each scan is associated to a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans = [str(i) for i in range(100)]\n",
    "grades = [\"1\" for _ in range(30)] + [\"3\" for _ in range(70)]\n",
    "splits = split(scans, grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scan</th>\n",
       "      <th>grade</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scan grade  split\n",
       "0    0     1  valid\n",
       "1    1     1  train\n",
       "2    2     1  valid\n",
       "3    3     1  train\n",
       "4    4     1  train\n",
       "5    5     1  train\n",
       "6    6     1  train\n",
       "7    7     1  train\n",
       "8    8     1  train\n",
       "9    9     1  train"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"scan\": scans, \"grade\": grades, \"split\": splits})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df[\"split\"] == \"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportions of grades 1 and 3 are preserved in each subset as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df[\"split\"] == \"valid\") & (df[\"grade\"] == \"3\")]) / len(\n",
    "    df.loc[df[\"split\"] == \"valid\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _remove_doubles(\n",
    "    scans: Sequence[str], grades: Sequence[str]\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    scans_res = []\n",
    "    grades_res = []\n",
    "    for scan, grade in zip(scans, grades):\n",
    "        if scan not in scans_res:\n",
    "            scans_res.append(scan)\n",
    "            grades_res.append(grade)\n",
    "    return scans_res, grades_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_csv(\n",
    "    csv_path: Path, data_path: Path, label_func: Optional[Callable[[Path], bool]] = None\n",
    ") -> pd.DataFrame:\n",
    "    label_func = ifnone(label_func, lambda x: x.parts[-3])\n",
    "    scans, grades = get_items(data_path, label_func, extensions=[\".png\"])\n",
    "    scans = list(map(lambda x: x.parent.name, scans))\n",
    "    scans, grades = _remove_doubles(scans, grades)\n",
    "    splits = split(scans, grades)\n",
    "    df = pd.DataFrame({\"scan\": scans, \"grade\": grades, \"split\": splits})\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a csv that contains all scan names, with the associated grade and subset they are in. Scans are found in the folder contained in `data_path` (`Path` object). Doubles are deleted. The file is then stored in `csv_path`. You can specify a `label_func` to compute how the grade is to be extracted from the path to a patch. Returns the corresponding dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scan</th>\n",
       "      <th>grade</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CF_PACS04rescan_07P0208</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CF_PACS05HE_03026-04H2669</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CF_PACS04rescan_06P1306</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CF_PACS04rescan_07P0201</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CF_PACS05HE_06003-172.608I</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CF_PACS05HE_08034-A03.11622B3</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CF_PACS04rescan_06P242</td>\n",
       "      <td>3</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CF_PACS04rescan_06P0912</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            scan grade  split\n",
       "0        CF_PACS04rescan_07P0208     1  train\n",
       "1      CF_PACS05HE_03026-04H2669     1  valid\n",
       "2        CF_PACS04rescan_06P1306     1  train\n",
       "3        CF_PACS04rescan_07P0201     1  train\n",
       "4     CF_PACS05HE_06003-172.608I     3  train\n",
       "5  CF_PACS05HE_08034-A03.11622B3     3  train\n",
       "6         CF_PACS04rescan_06P242     3  valid\n",
       "7        CF_PACS04rescan_06P0912     3  train"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_csv(data.parent / \"sample.csv\", data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 16_data.modules.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
