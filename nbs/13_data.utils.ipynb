{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data utils\n",
    "> Utility functions to manipulate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.data.loaders import ImageLoader\n",
    "from grade_classif.imports import *\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def np_to_tensor(x: NDArray[(Any, ...), Number], tensor_type: str) -> torch.Tensor:\n",
    "    if tensor_type == \"image\" or tensor_type == \"slide\":\n",
    "        x = x.transpose(2, 0, 1)\n",
    "        if x.dtype == np.uint8:\n",
    "            x = x.astype(np.float32) / 255\n",
    "    x = torch.tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a numpy ndarray into a tensor. If `tensor_type` is `'image'`, put channel first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def show_img(\n",
    "    x: NDArray[(Any, Any, 3), Number],\n",
    "    ax: Optional[Axes] = None,\n",
    "    figsize: Tuple[int, int] = (3, 3),\n",
    "    title: Optional[str] = None,\n",
    "    hide_axis: bool = True,\n",
    "    cmap: str = \"viridis\",\n",
    "    alpha: Optional[float]=None,\n",
    "    **kwargs\n",
    ") -> Axes:\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    xtr = dict(cmap=cmap, alpha=alpha, **kwargs)\n",
    "    ax.imshow(x, **xtr)\n",
    "    if hide_axis:\n",
    "        ax.axis(\"off\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convienience function for plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_batches(\n",
    "    folder: Path,\n",
    "    bs: int = 16,\n",
    "    device: str = \"cpu\",\n",
    "    filt: Optional[Callable[[Path], bool]] = None,\n",
    ") -> Iterable[torch.Tensor]:\n",
    "    x = []\n",
    "    image_loader = ImageLoader()\n",
    "    for fn in folder.iterdir():\n",
    "        if filt is not None and not filt(fn):\n",
    "            continue\n",
    "        if len(x) < bs:\n",
    "            img = image_loader(fn)\n",
    "            img = np_to_tensor(img, \"image\").to(device)\n",
    "            x.append(img)\n",
    "        else:\n",
    "            yield torch.stack(x)\n",
    "            x = []\n",
    "    if x != []:\n",
    "        yield torch.stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator function that loads images from `folder` in batches of size `bs` on `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LabelSlideBalancedRandomSampler(Sampler[int]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        labels: Sequence[str],\n",
    "        patch_slides: Sequence[str],\n",
    "        num_samples,\n",
    "        replacement: bool = True,\n",
    "        generator=None,\n",
    "    ):\n",
    "        assert len(labels) == len(\n",
    "            patch_slides\n",
    "        ), \"labels and slides must have same length\"\n",
    "        self.classes, self.labels = np.unique(labels, return_inverse=True)\n",
    "        self.classes = np.arange(len(self.classes))\n",
    "        self.slides, self.patch_slides = np.unique(patch_slides, return_inverse=True)\n",
    "        self.slides = np.arange(len(self.slides))\n",
    "        self.num_samples = num_samples\n",
    "        self.replacement = replacement\n",
    "        self.generator = generator\n",
    "\n",
    "    def get_idxs(self):\n",
    "        tree = {}\n",
    "        for cl in self.classes:\n",
    "            tree[cl] = {}\n",
    "            patch_slides = self.patch_slides[self.labels == cl]\n",
    "            for slide in np.unique(patch_slides):\n",
    "                tree[cl][slide] = (\n",
    "                    np.argwhere(self.patch_slides == slide).squeeze(1).tolist()\n",
    "                )\n",
    "        idxs = []\n",
    "        for _ in range(self.num_samples):\n",
    "            x = torch.rand(3, generator=self.generator)\n",
    "            classes = list(tree.keys())\n",
    "            cl = classes[int(x[0]*len(classes))]\n",
    "            cl_slides = tree[cl]\n",
    "            slides = list(cl_slides.keys())\n",
    "            slide = slides[int(x[1]*len(slides))]\n",
    "            slide_patches = cl_slides[slide]\n",
    "            idx = int(x[2]*len(slide_patches))\n",
    "            if self.replacement:\n",
    "                patch = slide_patches[idx]\n",
    "            else:\n",
    "                patch = slide_patches.pop(idx)\n",
    "                if len(slide_patches) == 0:\n",
    "                    cl_slides.pop(slide)\n",
    "                    if len(cl_slides) == 0:\n",
    "                        tree.pop(cl)\n",
    "            idxs.append(patch)\n",
    "        return idxs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.get_idxs())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 16_data.modules.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
