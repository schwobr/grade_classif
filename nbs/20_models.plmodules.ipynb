{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.plmodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2self.log(\"loss_1\", loss1, on_step=False, on_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PytorchLightning Modules\n",
    "> Modules implementing <a href=\\\"https://pytorch-lightning.readthedocs.io/en/0.6.0/lightning-module.html\\\">LightningModule</a> interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import ConfusionMatrix, ROC\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler, SimpleProfiler\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from grade_classif.core import ifnone\n",
    "from grade_classif.data.color import ColorConverter, rgb_to_lab\n",
    "from grade_classif.imports import *\n",
    "from grade_classif.models.losses import BCE, FocalLoss\n",
    "from grade_classif.models.metrics import pcc, ssim, ClassifMetrics\n",
    "from grade_classif.models.modules import *\n",
    "from grade_classif.models.utils import (\n",
    "    gaussian_mask,\n",
    "    get_num_features,\n",
    "    get_sizes,\n",
    "    named_leaf_modules\n",
    ")\n",
    "from timm.models.vision_transformer import Block\n",
    "from timm.models.layers.weight_init import trunc_normal_\n",
    "from sklearn.metrics import auc\n",
    "from pytorch_lightning.tuner.lr_finder import lr_find\n",
    "from pytorch_lightning.trainer.states import RunningStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_loss(\n",
    "    loss_name: str,\n",
    "    weights: Sequence[float],\n",
    "    reduction: str,\n",
    "    device: str = \"cpu\",\n",
    "    nc: int = 2,\n",
    ") -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "    if weights is not None:\n",
    "        weights = torch.tensor(weights, device=device)\n",
    "    if loss_name == \"cross-entropy\":\n",
    "        loss = nn.CrossEntropyLoss(\n",
    "            weights,\n",
    "            reduction=reduction,\n",
    "        )\n",
    "    elif loss_name == \"bce\":\n",
    "        loss = BCE(\n",
    "            reduction=reduction, pos_weight=weights\n",
    "        )\n",
    "    elif loss_name == \"mse\":\n",
    "        loss = nn.MSELoss(reduction=reduction)\n",
    "    elif loss_name == \"focal\":\n",
    "        loss = FocalLoss(reduction=reduction)\n",
    "    return loss.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_scheduler(\n",
    "    opt: Optimizer, name: str, total_steps: int, lr: float\n",
    ") -> torch.optim.lr_scheduler._LRScheduler:\n",
    "    if name == \"one-cycle\":\n",
    "        sched = {\n",
    "            \"scheduler\": OneCycleLR(opt, lr, total_steps=total_steps),\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "    elif name == \"cosine-anneal\":\n",
    "        sched = {\"scheduler\": CosineAnnealingLR(opt, total_steps), \"interval\": \"step\"}\n",
    "    elif name == \"reduce-on-plateau\":\n",
    "        sched = {\n",
    "            \"scheduler\": ReduceLROnPlateau(opt, patience=3),\n",
    "            \"interval\": \"epoch\",\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "    return sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_base_model(model_name: str, pretrained: bool = True, size=299, **kwargs):\n",
    "    if \"cbr\" in model_name:\n",
    "        args = map(int, model_name.split(\"_\")[1:])\n",
    "        base_model = CBR(*args, **kwargs)\n",
    "        cut = -3\n",
    "    elif \"sasa\" in model_name:\n",
    "        args = map(int, model_name.split(\"_\")[1:])\n",
    "        base_model = SASA(*args, **kwargs)\n",
    "        cut = -3\n",
    "    elif \"sanet\" in model_name:\n",
    "        splits = model_name.split(\"_\")\n",
    "        kernel_size = int(splits[-1])\n",
    "        base_model = globals()[splits[0]](kernel_size, **kwargs)\n",
    "        cut = -2\n",
    "    elif \"vit\" in model_name:\n",
    "        splits = model_name.split(\"_\")\n",
    "        base_model = VisionTransformer(\n",
    "            img_size=size,\n",
    "            patch_size=splits[1],\n",
    "            embed_dim=splits[2],\n",
    "            depth=splits[3],\n",
    "            num_heads=splits[4],\n",
    "            qkv_bias=True,\n",
    "        )\n",
    "        cut = -2\n",
    "    else:\n",
    "        base_model = timm.create_model(model_name, pretrained=pretrained, **kwargs)\n",
    "        cut = -2\n",
    "    base_model = nn.Sequential(*list(base_model.children())[:cut])\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_head(n_features: int, n_classes: int, dropout: float = 0.5):\n",
    "    head = [nn.AdaptiveAvgPool2d(1), nn.Flatten()]\n",
    "    head += bn_drop_lin(n_features, n_features, p=dropout / 2) + bn_drop_lin(\n",
    "        n_features, n_classes, p=dropout\n",
    "    )\n",
    "    head = nn.Sequential(*head)\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModule(pl.LightningModule):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        size: int = 299,\n",
    "        gpus: Optional[List[int]] = None,\n",
    "        model: Optional[str] = None,\n",
    "        normalizer: Optional[str] = None,\n",
    "        savedir: Optional[Union[Path, str]] = None,\n",
    "        level: int = None,\n",
    "        resume_version: Optional[str] = None,\n",
    "        resume_checkpoint: Optional[int] = None,\n",
    "        sample_mode: int = 0,\n",
    "        weights: Optional[Sequence[float]] = None,\n",
    "        epochs: int = 5,\n",
    "        loss: str = \"mse\",\n",
    "        reduction: str = \"mean\",\n",
    "        lr: float = 1e-3,\n",
    "        wd: float = 0.01,\n",
    "        train_percent: float = 1.0,\n",
    "        sched: Optional[str] = None,\n",
    "        rand_weights: bool = False,\n",
    "        dropout: float = 0.5,\n",
    "        version: Optional[str] = None,\n",
    "        open_mode: str = \"RGB\",\n",
    "        mixed_precision: bool = False,\n",
    "        auto_lr_find: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if model is None and normalizer is None:\n",
    "            raise AttributeError(\n",
    "                \"at least one of model and normalizer should ne specified\"\n",
    "            )\n",
    "        self.main_device = \"cpu\" if gpus is None else f\"cuda:{gpus[0]}\"\n",
    "        # self.main_device = 'cuda:1'\n",
    "        model_type = \"normalizer\" if isinstance(self, Normalizer) else \"classifier\"\n",
    "        savedir = ifnone(savedir, Path.cwd() / \"log\")\n",
    "        level = ifnone(level, -1)\n",
    "        self.save_path = Path(savedir) / f\"level_{level}\"\n",
    "        self.save_path = self.save_path / f\"{model_type}/{model}\"\n",
    "        self.example_inputs = torch.rand(\n",
    "            2, 3, size, size, dtype=torch.float, device=self.main_device\n",
    "        )\n",
    "        self.color_converter = ColorConverter(open_mode)\n",
    "        self.callbacks = []\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def post_init(self):\n",
    "        leaf_modules = named_leaf_modules(self)\n",
    "        size = self.hparams.size\n",
    "        self.sizes, self.leaf_modules = get_sizes(\n",
    "            self, input_shape=(3, size, size), leaf_modules=leaf_modules\n",
    "        )\n",
    "        self = self.to(self.main_device)\n",
    "        if self.hparams.resume_version is not None:\n",
    "            self.load(\n",
    "                self.hparams.resume_version, ckpt_epoch=self.hparams.resume_checkpoint\n",
    "            )\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self.train()\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        lr = self.opt.param_groups[-1][\"lr\"]\n",
    "        log = {\"train_loss\": loss.detach(), \"learning_rate\": lr}\n",
    "        self.log_dict(log, on_step=True, on_epoch=False)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x).detach()\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return {\"loss\": loss, \"preds\": y_hat.cpu(), \"labels\": y.cpu()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, torch.Tensor]]):\n",
    "        # OPTIONAL\n",
    "        val_loss = torch.mean(torch.stack([output[\"loss\"] for output in outputs]))\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def test_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        return self.validation_step(batch, batch_nb)\n",
    "\n",
    "    def on_fit_end(self):\n",
    "        try:\n",
    "            path = self.trainer.checkpoint_callbacks[0].best_model_path\n",
    "        except IndexError:\n",
    "            print(\"No checkpoint callback found, skipping export.\")\n",
    "            return\n",
    "        checkpoint = torch.load(path, map_location=self.main_device)\n",
    "        self.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        self = self.to(self.main_device)\n",
    "        self.export_to_torchscript()\n",
    "\n",
    "    def configure_optimizers(self) -> Union[Optimizer, Dict[str, Any]]:\n",
    "        # REQUIRED\n",
    "        hparams = self.hparams\n",
    "        if not hasattr(self, \"loss\"):\n",
    "            self.loss = _get_loss(\n",
    "                hparams.loss,\n",
    "                hparams.weights,\n",
    "                hparams.reduction,\n",
    "                device=self.main_device,\n",
    "            )\n",
    "        self.lr = hparams.lr\n",
    "        self.wd = hparams.wd\n",
    "        self.opt = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.lr, weight_decay=self.wd\n",
    "        )\n",
    "        n_train_dl = len(self.trainer.datamodule.train_dataloader())\n",
    "        n_iter = int(hparams.epochs * n_train_dl)\n",
    "        sched = _get_scheduler(self.opt, hparams.sched, n_iter, self.lr)\n",
    "        if sched is None:\n",
    "            return self.opt\n",
    "        else:\n",
    "            self.sched = sched[\"scheduler\"]\n",
    "            return {\"optimizer\": self.opt, \"lr_scheduler\": sched}\n",
    "\n",
    "    \"\"\"def on_after_backward(self):\n",
    "        for pg in self.opt.param_groups:\n",
    "            for p in pg[\"params\"]:\n",
    "                p.data.mul_(1 - self.wd * pg[\"lr\"])\"\"\"\n",
    "\n",
    "    def load(self, version: str, ckpt_epoch: int = None):\n",
    "        \"\"\"\n",
    "        Load a specific `version` of current model, stored in\n",
    "        `self.save_path/lightning_logs`. If multiple checkpoints have been\n",
    "        stored, `ckpt_epoch` can be specified to load a specific epoch. Else\n",
    "        the latest epoch is loaded.\n",
    "        \"\"\"\n",
    "        save_dir = self.save_path / f\"lightning_logs/version_{version}/checkpoints\"\n",
    "        path = (\n",
    "            list(save_dir.iterdir())[-1]\n",
    "            if ckpt_epoch is None\n",
    "            else save_dir / f\"_ckpt_epoch_{ckpt_epoch}.ckpt\"\n",
    "        )\n",
    "        if not path.exists():\n",
    "            path = save_dir / f\"epoch={ckpt_epoch}.ckpt\"\n",
    "        checkpoint = torch.load(path, map_location=self.main_device)\n",
    "        missing, unexpected = self.load_state_dict(\n",
    "            checkpoint[\"state_dict\"], strict=False\n",
    "        )\n",
    "        if len(missing):\n",
    "            message = f\"Warning, missing keys in state dict :\\n{'; '.join(missing)}\"\n",
    "            warnings.warn(message)\n",
    "        if len(unexpected):\n",
    "            message = (\n",
    "                f\"Warning, unexpected keys in state dict :\\n{'; '.join(unexpected)}\"\n",
    "            )\n",
    "            warnings.warn(message)\n",
    "        self.version = version\n",
    "\n",
    "    def my_summarize(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get a DataFrame containing the list of all leaf modules of current\n",
    "        model, with their corresponding output shape.\n",
    "        \"\"\"\n",
    "        named_modules = list(map(lambda x: x.name, self.leaf_modules))\n",
    "        summary = pd.DataFrame({\"Name\": named_modules, \"Output Shape\": self.sizes})\n",
    "        return summary\n",
    "    \n",
    "    def on_save_checkpoint(self, checkpoint: Dict[str, Any]):\n",
    "        dirpath = Path(self.ckpt_callback.dirpath).parent\n",
    "        self.export_to_torchscript(file_path=dirpath/f\"{self.current_epoch}.pt\")\n",
    "\n",
    "    def fit(self, dm: pl.LightningDataModule, monitor=\"val_loss\", **kwargs):\n",
    "        \"\"\"\n",
    "        Fit the model using parameters stored in `hparams`.\n",
    "        \"\"\"\n",
    "        logger = CometLogger(\n",
    "            api_key=os.environ[\"COMET_API_KEY\"],\n",
    "            workspace=\"schwobr\",\n",
    "            save_dir=self.save_path,\n",
    "            project_name=\"grade-classif\",\n",
    "            auto_metric_logging=False,\n",
    "        )\n",
    "        logger.experiment.add_tag(\"norm\" if isinstance(self, Normalizer) else \"classif\")\n",
    "        ckpt_path = (\n",
    "            self.save_path\n",
    "            / \"lightning_logs\"\n",
    "            / f\"version_{logger.version}\"\n",
    "            / \"checkpoints\"\n",
    "        )\n",
    "        if not ckpt_path.is_dir():\n",
    "            ckpt_path.mkdir(parents=True)\n",
    "        mode = \"min\" if \"loss\" in monitor or \"err\" in monitor else \"max\"\n",
    "        self.ckpt_callback = ModelCheckpoint(\n",
    "            dirpath=ckpt_path,\n",
    "            save_top_k=3,\n",
    "            monitor=monitor,\n",
    "            save_last=True,\n",
    "            mode=mode,\n",
    "            filename=\"{epoch}\",\n",
    "        )\n",
    "        profiler = None\n",
    "        if self.hparams.profiler == \"simple\":\n",
    "            profiler = SimpleProfiler(ckpt_path.parent / \"profiler_logs.txt\")\n",
    "        elif self.hparams.profiler == \"advanced\":\n",
    "            profiler = AdvancedProfiler(ckpt_path.parent / \"profiler_logs.txt\")\n",
    "        dm.setup()\n",
    "        precision = 16 if self.hparams.mixed_precision or self.hparams.deepspeed else 32\n",
    "        plugins = \"deepspeed\" if self.hparams.deepspeed else None\n",
    "        callbacks = self.callbacks + [self.ckpt_callback]\n",
    "        n = len(dm.train_dataloader())\n",
    "        log_every_n_steps = min(50, max(1, n // 10))\n",
    "        trainer = pl.Trainer(\n",
    "            gpus=self.hparams.gpus,\n",
    "            callbacks=callbacks,\n",
    "            logger=logger,\n",
    "            precision=precision,\n",
    "            min_epochs=self.hparams.epochs,\n",
    "            max_epochs=self.hparams.epochs,\n",
    "            plugins=plugins,\n",
    "            log_every_n_steps=log_every_n_steps,\n",
    "            profiler=profiler,\n",
    "            weights_summary=None,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if self.hparams.auto_lr_find:\n",
    "            lr_finder = lr_find(trainer, self, datamodule=dm)\n",
    "            fig = lr_finder.plot(suggest=True)\n",
    "            lr = lr_finder.suggestion()\n",
    "            print(f\"Suggested learning rate is {lr}.\")\n",
    "            self.hparams.lr = lr\n",
    "            self.logger.experiment.log_parameter(\"lr\", lr)\n",
    "            trainer.logger.experiment.log_figure(figure_name=\"LR finder\", figure=fig)\n",
    "        self.version = trainer.logger.version\n",
    "        trainer.fit(self, dm)\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Make a prediction on batch `x`.\n",
    "        \"\"\"\n",
    "        return self.eval()(x)\n",
    "\n",
    "    def export_to_torchscript(self, file_path: Optional[str] = None):\n",
    "        save_dir = self.save_path / f\"lightning_logs/version_{self.version}\"\n",
    "        file_path = ifnone(file_path, save_dir / \"best_model.pt\")\n",
    "        self.to_torchscript(\n",
    "            file_path=str(file_path),\n",
    "            method=\"trace\",\n",
    "            example_inputs=self.example_inputs,\n",
    "        )\n",
    "\n",
    "    def _create_normalizer(self):\n",
    "        hparams = self.hparams\n",
    "        if hparams.normalizer is not None:\n",
    "            norm = torch.jit.load(hparams.normalizer, map_location=\"cpu\")\n",
    "            for p in norm.parameters():\n",
    "                p.requires_grad = False\n",
    "            norm = norm.eval()\n",
    "            self.norm = norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class for all classes implementing [`LightningModule`](https://pytorch-lightning.readthedocs.io/en/0.6.0/lightning-module.html) interface. Defines a lot of convenience function to be used by children classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BaseModule.load\" class=\"doc_header\"><code>BaseModule.load</code><a href=\"__main__.py#L139\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BaseModule.load</code>(**`version`**:`str`, **`ckpt_epoch`**:`int`=*`None`*)\n",
       "\n",
       "Load a specific `version` of current model, stored in\n",
       "`self.save_path/lightning_logs`. If multiple checkpoints have been\n",
       "stored, `ckpt_epoch` can be specified to load a specific epoch. Else\n",
       "the latest epoch is loaded."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BaseModule.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BaseModule.my_summarize\" class=\"doc_header\"><code>BaseModule.my_summarize</code><a href=\"__main__.py#L168\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BaseModule.my_summarize</code>()\n",
       "\n",
       "Get a DataFrame containing the list of all leaf modules of current\n",
       "model, with their corresponding output shape."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BaseModule.my_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BaseModule.fit\" class=\"doc_header\"><code>BaseModule.fit</code><a href=\"__main__.py#L177\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BaseModule.fit</code>(**`dm`**:`LightningDataModule`, **`monitor`**=*`'val_loss'`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Fit the model using parameters stored in [`hparams`](/grade_classif/params.parser.html#hparams)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BaseModule.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BaseModule.predict\" class=\"doc_header\"><code>BaseModule.predict</code><a href=\"__main__.py#L239\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BaseModule.predict</code>(**`x`**:`Tensor`)\n",
       "\n",
       "Make a prediction on batch `x`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BaseModule.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_keys_in_list_and_apply(\n",
    "    list_of_dicts: Sequence[Dict[str, Any]],\n",
    "    *keys,\n",
    "    apply_func: Optional[Callable[[Any], Any]] = None\n",
    ") -> List[List[Any]]:\n",
    "    res = []\n",
    "    for k in keys:\n",
    "        sub_list = []\n",
    "        for d in list_of_dicts:\n",
    "            sub_list.append(d[k])\n",
    "        if apply_func is not None:\n",
    "            sub_list = apply_func(sub_list)\n",
    "        res.append(sub_list)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Normalizer(BaseModule):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        input_shape = (3, self.hparams.size, self.hparams.size)\n",
    "        self.unet = DynamicUnet(\n",
    "            self.hparams.model,\n",
    "            n_classes=3,\n",
    "            input_shape=input_shape,\n",
    "            pretrained=not self.hparams.rand_weights,\n",
    "        )\n",
    "        self.post_init()\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        x, y = next(iter(self.train_dataloader()))\n",
    "        for img in x:\n",
    "            self.logger.experiment.log_image(\n",
    "                img, image_channels=\"first\", image_minmax=(0.0, 1.0)\n",
    "            )\n",
    "        for img in y:\n",
    "            self.logger.experiment.log_image(\n",
    "                img, image_channels=\"first\", image_minmax=(0.0, 1.0)\n",
    "            )\n",
    "            \n",
    "    def on_epoch_start(self):\n",
    "        for tfm in self.trainer.datamodule.data.valid.tfms:\n",
    "            if \"Deterministic\" in str(type(tfm)):\n",
    "                tfm.n = 0\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.color_converter(x).detach()\n",
    "        return self.unet(x)\n",
    "\n",
    "    def show_results(\n",
    "        self, ds: Dataset, n: int = 16, imgsize: int = 4, title: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plot `n` predictions from the normalizer using samples from dataset\n",
    "        `ds`. Each line will contain input, target and prediction images (in\n",
    "        that order).\n",
    "        \"\"\"\n",
    "        n = min(n, self.bs)\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(imgsize * 3, imgsize * n))\n",
    "        idxs = np.random.choice(np.arange(len(ds)), size=n, replace=False)\n",
    "        inputs = []\n",
    "        targs = []\n",
    "        for idx in idxs:\n",
    "            x, y = ds[idx]\n",
    "            inputs.append(x)\n",
    "            targs.append(y)\n",
    "        inputs = torch.stack(inputs).to(next(self.main_device))\n",
    "        preds = self.predict(inputs).clamp(0, 1)\n",
    "        for ax_r, x, y, z in zip(axs, inputs, targs, preds):\n",
    "            x = x.cpu().numpy().transpose(1, 2, 0)\n",
    "            y = y.numpy().transpose(1, 2, 0)\n",
    "            z = z.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "            show_img(x, ax=ax_r[0])\n",
    "            show_img(y, ax=ax_r[1])\n",
    "            show_img(z, ax=ax_r[2])\n",
    "        title = ifnone(title, \"input/target/prediction\")\n",
    "        fig.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def freeze_encoder(self):\n",
    "        \"\"\"\n",
    "        Freeze the encoder part of the normalizer.\n",
    "        \"\"\"\n",
    "        for m in self.leaf_modules:\n",
    "            if \"encoder\" in m.name and not isinstance(m, nn.BatchNorm2d):\n",
    "                for param in m.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def init_bn(self):\n",
    "        \"\"\"\n",
    "        Initialize BatchNorm layers with bias `1e-3` and weights `1`.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                with torch.no_grad():\n",
    "                    m.bias.fill_(1e-3)\n",
    "                    m.weight.fill_(1.0)\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        ret = super().validation_step(batch, batch_nb)\n",
    "        y, y_hat = ret.pop(\"labels\"), ret.pop(\"preds\")\n",
    "        bs = y.shape[0]\n",
    "        y = rgb_to_lab(y.detach())\n",
    "        y_hat = rgb_to_lab(y_hat.detach())\n",
    "        ret[\"mu_x\"] = torch.mean(y[:, 0], axis=(1, 2)).float()\n",
    "        ret[\"sigma_x\"] = torch.std(y[:, 0], axis=(1, 2)).float()\n",
    "        ret[\"mu_y\"] = torch.mean(y_hat[:, 0], axis=(1, 2)).float()\n",
    "        ret[\"sigma_y\"] = torch.std(y_hat[:, 0], axis=(1, 2)).float()\n",
    "        ret[\"mu_xy\"] = torch.mean(y[:, 0] * y_hat[:, 0], axis=(1, 2)).float()\n",
    "        return ret\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, torch.Tensor]]):\n",
    "        # OPTIONAL\n",
    "        super().validation_epoch_end(outputs)\n",
    "        log = {}\n",
    "        mu_x, sigma_x, mu_y, sigma_y, mu_xy = _get_keys_in_list_and_apply(\n",
    "            outputs, \"mu_x\", \"sigma_x\", \"mu_y\", \"sigma_y\", \"mu_xy\", apply_func=torch.cat\n",
    "        )\n",
    "        m_ssim = ssim(mu_x, sigma_x, mu_y, sigma_y, mu_xy)\n",
    "        m_pcc = pcc(mu_x, sigma_x, mu_y, sigma_y, mu_xy)\n",
    "        m_cd = sigma_y / mu_y - sigma_x / mu_x\n",
    "        log[\"ssim\"] = m_ssim.mean()\n",
    "        log[\"pcc\"] = m_pcc.mean()\n",
    "        log[\"cd\"] = m_cd.mean()\n",
    "        self.log_dict(log)\n",
    "\n",
    "    def test_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        return self.validation_step(batch, batch_nb)\n",
    "\n",
    "    def test_epoch_end(self, outputs: List[Dict[str, torch.tensor]]):\n",
    "        return self.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module containing a UNet normalizer. Takes grayscale images as inputs and their corresponding colored version as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Normalizer.show_results\" class=\"doc_header\"><code>Normalizer.show_results</code><a href=\"__main__.py#L36\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Normalizer.show_results</code>(**`ds`**:`Dataset`, **`n`**:`int`=*`16`*, **`imgsize`**:`int`=*`4`*, **`title`**:`Optional`\\[`str`\\]=*`None`*)\n",
       "\n",
       "Plot `n` predictions from the normalizer using samples from dataset\n",
       "`ds`. Each line will contain input, target and prediction images (in\n",
       "that order)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Normalizer.show_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Normalizer.freeze_encoder\" class=\"doc_header\"><code>Normalizer.freeze_encoder</code><a href=\"__main__.py#L66\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Normalizer.freeze_encoder</code>()\n",
       "\n",
       "Freeze the encoder part of the normalizer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Normalizer.freeze_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Normalizer.init_bn\" class=\"doc_header\"><code>Normalizer.init_bn</code><a href=\"__main__.py#L75\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Normalizer.init_bn</code>()\n",
       "\n",
       "Initialize BatchNorm layers with bias `1e-3` and weights `1`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Normalizer.init_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ClassifModule(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes: int = 2,\n",
    "        classes: Optional[Sequence[str]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.save_hyperparameters()\n",
    "        hparams = self.hparams\n",
    "        hparams.classes = ifnone(classes, list(range(n_classes)))\n",
    "        hparams.n_classes = len(\n",
    "            hparams.classes\n",
    "        )  # if classes is specified it superseeds n_classes\n",
    "        self.loss = _get_loss(\n",
    "            hparams.loss,\n",
    "            hparams.weights,\n",
    "            hparams.reduction,\n",
    "            device=self.main_device,\n",
    "            nc=n_classes,\n",
    "        )\n",
    "        self.cm = ConfusionMatrix(hparams.n_classes, compute_on_step=False)\n",
    "        self.roc = ROC(num_classes=hparams.n_classes, compute_on_step=False)\n",
    "        self.metrics = ClassifMetrics(\n",
    "            n_classes=hparams.n_classes, compute_on_step=False\n",
    "        )\n",
    "        self._create_normalizer()\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        x, _ = next(iter(self.train_dataloader()))\n",
    "        if hasattr(self, \"norm\"):\n",
    "            x = x.to(self.main_device)\n",
    "            x = self.norm(x).clamp(0, 1).detach().cpu()\n",
    "        for img in x:\n",
    "            self.logger.experiment.log_image(\n",
    "                img, image_channels=\"first\", image_minmax=(0.0, 1.0)\n",
    "            )\n",
    "\n",
    "    def log_distribution(self, y: torch.Tensor):\n",
    "        log = {}\n",
    "        for k, cl in enumerate(self.hparams.classes):\n",
    "            log[f\"n_{cl}\"] = (y == k).float().sum()\n",
    "        self.log_dict(log, on_step=False, on_epoch=True, reduce_fx=torch.sum)\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        ret = super().training_step(batch, batch_nb)\n",
    "        _, y = batch\n",
    "        self.log_distribution(y)\n",
    "        return ret\n",
    "\n",
    "    def update_metrics(self, y_hat: torch.Tensor, y: torch.Tensor):\n",
    "        y = y.to(self.main_device)\n",
    "        y_hat = y_hat.to(self.main_device)\n",
    "        self.roc(y_hat, y)\n",
    "        self.cm(y_hat, y)\n",
    "        self.metrics(y_hat, y)\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        ret = super().validation_step(batch, batch_nb)\n",
    "        y, y_hat = ret[\"labels\"], ret[\"preds\"]\n",
    "        y_hat = torch.softmax(y_hat, 1, torch.float)\n",
    "        self.update_metrics(y_hat, y)\n",
    "        ret[\"preds\"] = y_hat\n",
    "        return ret\n",
    "\n",
    "    def log_metrics(self, metrics, cm, roc, suffix: str = None):\n",
    "        log = {}\n",
    "        app = f\"_{suffix}\" if suffix is not None else \"\"\n",
    "        metric_dict = metrics.compute()\n",
    "        for metric in metric_dict:\n",
    "            val = metric_dict[metric]\n",
    "            if val.numel() == 1:\n",
    "                log[metric+app] = val\n",
    "            else:\n",
    "                for k, cl in enumerate(self.hparams.classes):\n",
    "                    c_name = f\"{metric}{app}_{cl}\"\n",
    "                    log[c_name] = val[k]\n",
    "                log[f\"{metric}{app}_mean\"] = val.mean()\n",
    "        if not self.trainer.running_sanity_check:\n",
    "            mat = cm.compute().cpu().numpy()\n",
    "            self.logger.experiment.log_confusion_matrix(\n",
    "                labels=self.hparams.classes,\n",
    "                matrix=mat,\n",
    "                step=self.global_step,\n",
    "                epoch=self.current_epoch,\n",
    "                file_name=f\"confusion_matrix{app}_{self.current_epoch}.json\",\n",
    "            )\n",
    "            fprs, tprs, _ = roc.compute()\n",
    "            for cl, fpr, tpr in zip(self.hparams.classes[::-1], fprs[::-1], tprs[::-1]):\n",
    "                fpr = fpr.cpu().numpy()\n",
    "                tpr = tpr.cpu().numpy()\n",
    "                self.logger.experiment.log_curve(\n",
    "                    f\"ROC{app}_{cl}_{self.current_epoch}\",\n",
    "                    x=fpr.tolist(),\n",
    "                    y=tpr.tolist(),\n",
    "                    step=self.current_epoch,\n",
    "                    overwrite=False,\n",
    "                )\n",
    "                log[f\"AUC{app}_{cl}\"] = auc(fpr, tpr)\n",
    "                if self.hparams.n_classes == 2:\n",
    "                    break\n",
    "        metrics.reset()\n",
    "        cm.reset()\n",
    "        roc.reset()\n",
    "        self.log_dict(log, on_step=False, on_epoch=True)\n",
    "\n",
    "    def log_preds(self, preds: torch.Tensor, labels: torch.Tensor):\n",
    "        preds = preds.numpy()\n",
    "        labels = labels.numpy()\n",
    "        items = self.trainer.datamodule.data.valid.items.astype(str)\n",
    "        data = {\n",
    "            f\"pred_{self.hparams.classes[k]}\": preds[:, k]\n",
    "            for k in range(preds.shape[1])\n",
    "        }\n",
    "        data[\"item\"] = items[: labels.shape[0]]\n",
    "        data[\"label\"] = labels\n",
    "        keys = [\"item\", \"label\"] + [f\"pred_{cl}\" for cl in self.hparams.classes]\n",
    "        df = pd.DataFrame(data=data, columns=keys)\n",
    "        savepath = self.save_path / f\"lightning_logs/version_{self.version}/preds\"\n",
    "        if not savepath.is_dir():\n",
    "            savepath.mkdir()\n",
    "        df.to_csv(savepath / f\"{self.current_epoch}.csv\", index=False)\n",
    "\n",
    "    def log_slide_metrics(self, preds: torch.Tensor, labels: torch.Tensor):\n",
    "        if not self.trainer.running_sanity_check:\n",
    "            items = self.trainer.datamodule.data.valid.items\n",
    "            patch_slides = np.vectorize(lambda x: x.parent.name)(items)\n",
    "            slides = np.unique(patch_slides)\n",
    "            slide_labels = []\n",
    "            slide_preds = []\n",
    "            roc = ROC(num_classes=self.hparams.n_classes, compute_on_step=False)\n",
    "            cm = ConfusionMatrix(self.hparams.n_classes, compute_on_step=False)\n",
    "            metrics = ClassifMetrics(\n",
    "                n_classes=self.hparams.n_classes, compute_on_step=False\n",
    "            )\n",
    "            for slide in slides:\n",
    "                idxs = np.argwhere(patch_slides == slide).squeeze()\n",
    "                label = labels[idxs][0]\n",
    "                pred = preds[idxs].mean(0)\n",
    "                slide_labels.append(label)\n",
    "                slide_preds.append(pred)\n",
    "            slide_labels = torch.stack(slide_labels)\n",
    "            slide_preds = torch.stack(slide_preds)\n",
    "            cm(slide_preds, slide_labels)\n",
    "            metrics(slide_preds, slide_labels)\n",
    "            roc(slide_preds, slide_labels)\n",
    "            self.log_metrics(metrics, cm, roc, suffix=\"slide\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, torch.Tensor]]):\n",
    "        # OPTIONAL\n",
    "        super().validation_epoch_end(outputs)\n",
    "        self.log_metrics(self.metrics, self.cm, self.roc)\n",
    "        preds, labels = _get_keys_in_list_and_apply(\n",
    "            outputs, \"preds\", \"labels\", apply_func=torch.cat\n",
    "        )\n",
    "        self.log_preds(preds, labels)\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pred = super().predict(x)\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageClassifModel(ClassifModule):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        hparams = self.hparams\n",
    "        in_chans = 3 if hparams.transforms < 10 else 9\n",
    "        self.base_model = _get_base_model(\n",
    "            hparams.model,\n",
    "            pretrained=not hparams.rand_weights,\n",
    "            in_chans=in_chans,\n",
    "            size=hparams.size,\n",
    "        )\n",
    "        nf = get_num_features(self.base_model)\n",
    "        self.head = _get_head(nf, hparams.n_classes, dropout=hparams.dropout)\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            if hasattr(self, \"norm\"):\n",
    "                x = self.norm(x)\n",
    "            x = self.color_converter(x)\n",
    "        x = self.base_model(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def freeze_base(self):\n",
    "        \"\"\"\n",
    "        Freeze the base model.\n",
    "        \"\"\"\n",
    "        for m in self.leaf_modules:\n",
    "            if \"base_model\" in m.name and not isinstance(m, nn.BatchNorm2d):\n",
    "                for param in m.parameters():\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, torch.Tensor]]):\n",
    "        super().validation_epoch_end(outputs)\n",
    "        self.log_slide_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RNNAttention(ClassifModule):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_glimpses: int = 3,\n",
    "        glimpse_size: int = 256,\n",
    "        gamma: float = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.save_hyperparameters()\n",
    "        hparams = self.hparams\n",
    "        nc = hparams.n_classes\n",
    "        self.t_x = nn.Sequential(*list(CBR(3, 64, 2).children())[:-2])\n",
    "        nf = get_num_features(self.t_x)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(nf, nc)\n",
    "        self.t_l = nn.Sequential(\n",
    "            nn.Linear(6, nf),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nf, 2 * nf),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * nf, nf),\n",
    "        )\n",
    "        self.t_a = nn.Sequential(\n",
    "            nn.Linear(nf, 2 * nf),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * nf, nf),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nf, 6),\n",
    "        )\n",
    "        self.final_head = nn.Sequential(\n",
    "            nn.Linear(nf * n_glimpses, nf), nn.ReLU(), nn.Linear(nf, nc)\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, X: torch.Tensor, l: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            if hasattr(self, \"norm\"):\n",
    "                X = self.norm(X)\n",
    "            X = self.color_converter(X)\n",
    "        Ai = gaussian_mask(\n",
    "            l[:, 0], l[:, 1], l[:, 2], self.hparams.glimpse_size, self.hparams.size\n",
    "        )\n",
    "        Aj = gaussian_mask(\n",
    "            l[:, 3], l[:, 4], l[:, 5], self.hparams.glimpse_size, self.hparams.size\n",
    "        )\n",
    "        x = Ai[:, None] @ X @ Aj.transpose(1, 2)[:, None]\n",
    "        fx = self.flat(self.t_x(x))\n",
    "        y = self.fc(fx)\n",
    "        fl = self.t_l(l)\n",
    "        l = torch.sigmoid(fx * fl)\n",
    "        l = self.t_a(l)\n",
    "        return fx, y, l\n",
    "\n",
    "    def compute_loss(\n",
    "        self, X: torch.Tensor, Y: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute the loss defined in the paper. Return the final slide-level\n",
    "        prediction as well.\n",
    "        \"\"\"\n",
    "        l0 = torch.tensor(\n",
    "            [[0, 0.5, self.hparams.size // self.hparams.glimpse_size] * 2] * X.shape[0],\n",
    "            device=self.main_device,\n",
    "        )\n",
    "        loss = 0\n",
    "        loss_prev = 0\n",
    "        preds = []\n",
    "        fts = []\n",
    "        for t in range(self.hparams.n_glimpses):\n",
    "            fx, y_hat, l = self(X, l0)\n",
    "            fts.append(fx)\n",
    "            loss += self.loss(y_hat, Y)\n",
    "            loss_a = ((torch.softmax(y_hat, 1, torch.float) - 0.5) ** 2).mean()\n",
    "            if t > 0:\n",
    "                loss -= loss_a - loss_prev / t\n",
    "            loss_prev += loss_a\n",
    "            loss += (self.hparams.gamma * torch.exp(-torch.abs(l - l0))).mean()\n",
    "            l0 = l.detach()\n",
    "        # bs x (C x n_glimpses)\n",
    "        fts = torch.cat(fts, dim=1)\n",
    "        Y_hat = self.final_head(fts)\n",
    "        loss += self.loss(Y_hat, Y)\n",
    "        return loss, Y_hat\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # REQUIRED\n",
    "        X, Y = batch\n",
    "        loss, _ = self.compute_loss(X, Y)\n",
    "        lr = self.opt.param_groups[-1][\"lr\"]\n",
    "        log = {\"train_loss\": loss, \"learning_rate\": lr}\n",
    "        self.log_dict(log)\n",
    "        self.log_distribution(Y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        loss, y_hat = self.compute_loss(x, y)\n",
    "        n = y.shape[0]\n",
    "        y_hat = torch.softmax(y_hat, 1, torch.float)\n",
    "        self.update_metrics(y_hat, y)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN model with attention as defined in [_Predicting Cancer with a Recurrent Visual Attention Model for Histopathology Images_](http://www.sfu.ca/~abentaie/papers/miccai18.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"RNNAttention.compute_loss\" class=\"doc_header\"><code>RNNAttention.compute_loss</code><a href=\"__main__.py#L58\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>RNNAttention.compute_loss</code>(**`X`**:`Tensor`, **`Y`**:`Tensor`)\n",
       "\n",
       "Compute the loss defined in the paper. Return the final slide-level\n",
       "prediction as well."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(RNNAttention.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_topk_idxs(probs, slide_idxs, k=1):\n",
    "    order = np.lexsort((probs, slide_idxs))\n",
    "    probs = probs[order]\n",
    "    slide_idxs = slide_idxs[order]\n",
    "    index = np.empty(len(probs), 'bool')\n",
    "    index[-k:] = True\n",
    "    index[:-k] = slide_idxs[k:] != slide_idxs[:-k]        \n",
    "    idxs = order[index]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_max_probs(probs, slide_idxs):\n",
    "    nmax = slide_idxs.max()\n",
    "    out = np.empty(nmax+1)\n",
    "    out[:] = np.nan\n",
    "    order = np.lexsort((probs, slide_idxs))\n",
    "    probs = probs[order]\n",
    "    slide_idxs = slide_idxs[order]\n",
    "    index = np.empty(len(probs), 'bool')\n",
    "    index[-1] = True\n",
    "    index[:-1] = slide_idxs[1:] != slide_idxs[:-1]\n",
    "    out[slide_idxs[index]] = probs[index]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MILModel(ImageClassifModel):\n",
    "    \"\"\"\"\"\"\n",
    "    def configure_optimizers(self):\n",
    "        opt = super().configure_optimizers()\n",
    "        if isinstance(opt, dict) and \"lr_scheduler\" in opt:\n",
    "            n_slides = len(self.trainer.datamodule.data.test.slides)\n",
    "            n_steps = (n_slides * self.hparams.topk) // self.hparams.batch_size\n",
    "            opt[\"lr_scheduler\"] = _get_scheduler(\n",
    "                opt[\"optimizer\"],\n",
    "                self.hparams.sched,\n",
    "                n_steps * self.hparams.epochs,\n",
    "                self.hparams.lr,\n",
    "            )\n",
    "            self.sched = opt[\"lr_scheduler\"][\"scheduler\"]\n",
    "        return opt\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.trainer.verbose_test = False\n",
    "        k = self.hparams.topk\n",
    "        self.trainer.testting = True\n",
    "        probs = _get_keys_in_list_and_apply(\n",
    "            self.trainer.run_evaluation(test_mode=True)[0],\n",
    "            \"probs\",\n",
    "            apply_func=torch.cat,\n",
    "        )[0]\n",
    "        self.trainer.testing = False\n",
    "        probs = probs.cpu().numpy()\n",
    "        test_ds = self.trainer.datamodule.data.test\n",
    "        slide_idxs = test_ds.slide_idxs\n",
    "        idxs = get_topk_idxs(probs, slide_idxs, k=k)\n",
    "        train_ds = self.trainer.datamodule.data.train\n",
    "        train_ds.items = test_ds.items.copy()[idxs]\n",
    "        train_ds.labels = test_ds.labels.copy()[idxs]\n",
    "        train_ds.slide_idxs = test_ds.slide_idxs.copy()[idxs]\n",
    "        self.trainer.reset_train_dataloader(self)\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, torch.Tensor]]):\n",
    "        # OPTIONAL\n",
    "        probs = _get_keys_in_list_and_apply(outputs, \"preds\", apply_func=torch.cat)[0][:, 1]\n",
    "        loss = _get_keys_in_list_and_apply(outputs, \"val_loss\", apply_func=torch.stack)[\n",
    "            0\n",
    "        ]\n",
    "        probs = probs.cpu().numpy()\n",
    "        log = {\"val_loss\": loss.mean()}\n",
    "        val_ds = self.trainer.datamodule.data.valid\n",
    "        preds = torch.as_tensor(get_max_probs(probs, val_ds.slide_idxs))\n",
    "        targs = torch.tensor(\n",
    "            [val_ds.label_loader(label) for label in val_ds.slide_labels]\n",
    "        )\n",
    "        self.metrics.reset()\n",
    "        self.cm.reset()\n",
    "        self.roc.reset()\n",
    "        self.update_metrics(preds, targs)\n",
    "        self.log_metrics(self.metrics, self.cm, self.roc)\n",
    "\n",
    "    def test_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        return self.validation_step(batch, batch_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RNNAggregator(ImageClassifModel):\n",
    "    def __init__(self, rnn_hidden_dims: int = 128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cpu()\n",
    "        self.freeze()\n",
    "        nf = get_num_features(self.base_model)\n",
    "        self.pooling = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten())\n",
    "        self.fc1 = nn.Linear(nf, rnn_hidden_dims)\n",
    "        self.fc2 = nn.Linear(rnn_hidden_dims, rnn_hidden_dims)\n",
    "        self.fc3 = nn.Linear(rnn_hidden_dims, self.hparams.n_classes)\n",
    "        self.act = nn.ReLU()\n",
    "        self.example_inputs = (\n",
    "            self.example_inputs,\n",
    "            torch.zeros(2, rnn_hidden_dims, device=self.main_device),\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "        self = self.to(self.main_device)\n",
    "\n",
    "    def post_init(self):\n",
    "        self = self.to(self.main_device)\n",
    "        if self.hparams.resume_version is not None:\n",
    "            self.load(\n",
    "                self.hparams.resume_version, ckpt_epoch=self.hparams.resume_checkpoint\n",
    "            )\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        with torch.no_grad():\n",
    "            if hasattr(self, \"norm\"):\n",
    "                x = self.norm(x)\n",
    "            x = self.color_converter(x)\n",
    "        x = self.base_model(x)\n",
    "        x = self.fc1(self.pooling(x))\n",
    "        state = self.fc2(state)\n",
    "        state = self.act(state + x)\n",
    "        y = self.fc3(state)\n",
    "        return y, state\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.base_model.eval()\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[List[torch.Tensor], torch.Tensor], batch_nb: int\n",
    "    ):\n",
    "        xs, y = batch\n",
    "        self.log_distribution(y)\n",
    "        state = torch.zeros(\n",
    "            y.shape[0], self.hparams.rnn_hidden_dims, device=self.main_device\n",
    "        )\n",
    "        for x in xs:\n",
    "            y_hat, state = self(x, state)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        lr = self.opt.param_groups[-1][\"lr\"]\n",
    "        log = {\"train_loss\": loss.detach(), \"learning_rate\": lr}\n",
    "        self.log_dict(log, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[List[torch.Tensor], torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        xs, y = batch\n",
    "        n = y.shape[0]\n",
    "        state = torch.zeros(n, self.hparams.rnn_hidden_dims, device=self.main_device)\n",
    "        for x in xs:\n",
    "            y_hat, state = self(x, state)\n",
    "        loss = self.loss(y_hat, y).detach()\n",
    "        ret = {\"loss\": loss}\n",
    "        y_hat = torch.softmax(y_hat, 1, torch.float)\n",
    "        y_hat = y_hat.argmax(dim=-1).view(n, -1)\n",
    "        y = y.view(n, -1)\n",
    "        for k, cl in enumerate(self.hparams.classes):\n",
    "            ret[f\"t_{cl}\"] = ((y_hat == k) & (y == k)).float().sum()\n",
    "            ret[f\"f_{cl}\"] = ((y_hat == k) & (y != k)).float().sum()\n",
    "        return ret\n",
    "\n",
    "    def predict(self, xs: List[torch.Tensor]) -> torch.Tensor:\n",
    "        state = torch.zeros(x.shape[0], self.hparams.rnn_hidden_dims)\n",
    "        for x in xs:\n",
    "            pred, state = super().predict(x, state)\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CoTeachingModel(ClassifModule):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        hparams = self.hparams\n",
    "        self.loss = _get_loss(\n",
    "            hparams.loss, hparams.weights, \"none\", device=self.main_device, nc=n_classes\n",
    "        )\n",
    "        base_model1 = _get_base_model(\n",
    "            hparams.model, pretrained=not hparams.rand_weights\n",
    "        )\n",
    "        base_model2 = _get_base_model(\n",
    "            hparams.model, pretrained=not hparams.rand_weights\n",
    "        )\n",
    "        nf = get_num_features(base_model1)\n",
    "        head1 = _get_head(nf, n_classes, dropout=hparams.dropout)\n",
    "        head2 = _get_head(nf, n_classes, dropout=hparams.dropout)\n",
    "        self.model1 = Classifier(base_model1, head1)\n",
    "        self.model2 = Classifier(base_model2, head2)\n",
    "        self.model2.apply(nn.init.kaiming_normal_)\n",
    "        self.cms = [\n",
    "            ConfusionMatrix(n_classes, compute_on_step=False),\n",
    "            ConfusionMatrix(n_classes, compute_on_step=False),\n",
    "        ]\n",
    "        self.rocs = [\n",
    "            ROC(num_classes=n_classes, compute_on_step=False),\n",
    "            ROC(num_classes=n_classes, compute_on_step=False),\n",
    "        ]\n",
    "        self.metrics = [\n",
    "            ClassifMetrics(n_classes=n_classes, compute_on_step=False),\n",
    "            ClassifMetrics(n_classes=n_classes, compute_on_step=False),\n",
    "        ]\n",
    "        self.post_init()\n",
    "\n",
    "    def configure_optimizers(self) -> Union[Optimizer, Dict[str, Any]]:\n",
    "        # REQUIRED\n",
    "        hparams = self.hparams\n",
    "        if not hasattr(self, \"loss\"):\n",
    "            self.loss = _get_loss(\n",
    "                hparams.loss,\n",
    "                hparams.weights,\n",
    "                hparams.reduction,\n",
    "                device=self.main_device,\n",
    "            )\n",
    "        self.lr = hparams.lr\n",
    "        self.wd = hparams.wd\n",
    "        self.opt1 = torch.optim.AdamW(\n",
    "            self.model1.parameters(), lr=self.lr, weight_decay=self.wd\n",
    "        )\n",
    "        self.opt1 = torch.optim.AdamW(\n",
    "            self.model2.parameters(), lr=self.lr, weight_decay=self.wd\n",
    "        )\n",
    "        n_train_dl = len(self.trainer.datamodule.train_dataloader())\n",
    "        n_iter = int(hparams.epochs * n_train_dl)\n",
    "        sched1 = _get_scheduler(self.opt1, hparams.sched, n_iter, self.lr)\n",
    "        sched2 = _get_scheduler(self.opt2, hparams.sched, n_iter, self.lr)\n",
    "        if sched1 is None:\n",
    "            return self.opt1, self.opt2\n",
    "        else:\n",
    "            self.sched1 = sched1[\"scheduler\"]\n",
    "            self.sched2 = sched2[\"scheduler\"]\n",
    "            return [self.opt1, self.opt2], [self.sched1, self.sched2]\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        epoch = self.trainer.current_epoch\n",
    "        epoch_max = self.trainer.max_epoch + 1\n",
    "        eps = self.hparams.forget_rate\n",
    "        n = self.hparams.forget_steps\n",
    "        self.remember_rate = 1 - eps * min(1 + (epoch - n) / (epoch_max - n), epoch / n)\n",
    "\n",
    "    def get_losses(self, batch: Tuple[torch.Tensor, torch.Tensor]):\n",
    "        x, y = batch\n",
    "        self.log_distribution(y)\n",
    "        num_remember = int(self.remember_rate * len(y))\n",
    "        y1 = self(x, model_idx=1)\n",
    "        y2 = self(x, model_idx=2)\n",
    "        loss1 = self.loss(y1, y).detach()\n",
    "        loss2 = self.loss(y2, y).detach()\n",
    "\n",
    "        if self.hparams.disagree_only:\n",
    "            pred1 = torch.softmax(y1, 1, torch.float).argmax(dim=1).detach()\n",
    "            pred2 = torch.softmax(y1, 1, torch.float).argmax(dim=1).detach()\n",
    "            disagree_idxs = (pred1 != pred2).cpu().data\n",
    "            idx1_sorted = np.lexsort((loss1.cpu().data, ~disagree_idxs))\n",
    "            idx2_sorted = np.lexsort((loss2.cpu().data, ~disagree_idxs))\n",
    "        else:\n",
    "            idx1_sorted = torch.argsort(loss1)\n",
    "            idx2_sorted = torch.argsort(loss2)\n",
    "\n",
    "        y1 = y1[idx2_sorted[:num_remember]]\n",
    "        y2 = y2[idx1_sorted[:num_remember]]\n",
    "        loss1 = self.loss(y1, y[idx2_sorted[:num_remember]]).mean()\n",
    "        loss2 = self.loss(y2, y[idx2_sorted[:num_remember]]).mean()\n",
    "        return loss1, loss2, y1.detach(), y2.detach()\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "        batch_nb: int,\n",
    "        optimizer_idx: int,\n",
    "    ) -> torch.Tensor:\n",
    "        # REQUIRED\n",
    "        loss1, loss2, _, _ = self.get_losses(batch)\n",
    "        opt1, opt2 = self.optimizers()\n",
    "        self.manual_backward(loss1, opt1)\n",
    "        self.manual_backward(loss2, opt2)\n",
    "        self.manual_optimizer_step(opt1)\n",
    "        self.manuam_optimizer_step(opt2)\n",
    "        lr = self.opt.param_groups[-1][\"lr\"]\n",
    "        log = {\n",
    "            \"train_loss1\": loss1.detach(),\n",
    "            \"train_loss2\": loss2.detach(),\n",
    "            \"learning_rate\": lr,\n",
    "        }\n",
    "        self.log_dict(log, on_step=True, on_epoch=False)\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_nb: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y1 = self(x, model_idx=1)\n",
    "        y2 = self(x, model_idx=2)\n",
    "        loss1 = self.loss(y1, y).detach()\n",
    "        loss2 = self.loss(y2, y).detach()\n",
    "        self.log(\"loss_1\", loss1, on_step=False, on_epoch=True)\n",
    "        self.log(\"loss_2\", loss2, on_step=False, on_epoch=True)\n",
    "        y1 = torch.softmax(y1, 1, torch.float)\n",
    "        y2 = torch.softmax(y2, 1, torch.float)\n",
    "        ret = {\"labels\": y, \"preds1\": y1, \"preds2\": y2}\n",
    "        for metrics, cm, roc, y_hat in zip(self.metrics, self.cms, self.rocs, (y1, y2)):\n",
    "            roc(y_hat, y)\n",
    "            metrics(y_hat, y)\n",
    "            cm(y_hat, y)\n",
    "        return ret\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, torch.Tensor]]):\n",
    "        # OPTIONAL\n",
    "        for n, metrics, cm, roc in zip((1, 2), self.metrics, self.cms, self.epochs):\n",
    "            self.log_metrics(metrics, cm, roc, suffix=n)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, model_idx=1) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            if hasattr(self, \"norm\"):\n",
    "                x = self.norm(x)\n",
    "            x = self.color_converter(x)\n",
    "        x = getattr(self, f\"model{model_idx}\")(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pred = super().predict(x)\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        return pred\n",
    "\n",
    "    def freeze_base(self):\n",
    "        \"\"\"\n",
    "        Freeze the base model.\n",
    "        \"\"\"\n",
    "        for m in self.leaf_modules:\n",
    "            if \"base_model\" in m.name and not isinstance(m, nn.BatchNorm2d):\n",
    "                for param in m.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def fit(self, dm: pl.LightningDataModule, **kwargs):\n",
    "        super().fit(dm, automatic_optimization=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class WSITransformer(ClassifModule):\n",
    "    def __init__(self, embed_dim=2048, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        params = self.hparams.model.split(\"_\")\n",
    "        assert params[0] == \"vit\", \"model must be VIT for Transformer.\"\n",
    "        assert (\n",
    "            len(params) == 4\n",
    "        ), \"model must be formatted as vit_{num_heads}_{mlp_ratio}_{depth}\"\n",
    "        num_heads, mlp_ratio, depth = map(int, params[1:])\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    dim=embed_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    drop=self.hparams.dropout,\n",
    "                    act_layer=nn.ReLU,\n",
    "                    norm_layer=nn.GroupNorm\n",
    "                )\n",
    "                for i in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, self.hparams.size * self.hparams.size + 1, embed_dim)\n",
    "        )\n",
    "        self.pos_drop = nn.Dropout(p=self.hparams.dropout)\n",
    "        self.head = nn.Linear(embed_dim, self.hparams.n_classes)\n",
    "        trunc_normal_(self.pos_embed)\n",
    "        trunc_normal_(self.cls_token)\n",
    "        self.apply(self._init_weights)\n",
    "        self.save_hyperparameters()\n",
    "        self.post_init()\n",
    "\n",
    "    def post_init(self):\n",
    "        leaf_modules = named_leaf_modules(self)\n",
    "        size = self.hparams.size\n",
    "        self.sizes, self.leaf_modules = get_sizes(\n",
    "            self,\n",
    "            input_shape=(size * size, self.hparams.embed_dim),\n",
    "            leaf_modules=leaf_modules,\n",
    "        )\n",
    "        self = self.to(self.main_device)\n",
    "        if self.hparams.resume_version is not None:\n",
    "            self.load(\n",
    "                self.hparams.resume_version, ckpt_epoch=self.hparams.resume_checkpoint\n",
    "            )\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)[:, 0]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 16_data.modules.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
