{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.plmodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.data.dataset import ImageClassifDataset, NormDataset\n",
    "from grade_classif.data.transforms import get_transforms\n",
    "from grade_classif.data.utils import show_img\n",
    "from grade_classif.models.utils import named_leaf_modules, get_sizes, get_num_features, gaussian_mask\n",
    "import grade_classif.models.modules as mods\n",
    "from grade_classif.models.losses import FocalLoss, BCE\n",
    "from grade_classif.core import ifnone\n",
    "from grade_classif.imports import *\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.logging import CometLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, RandomSampler, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_loss(loss_name, weight, reduction, device='cpu'):\n",
    "    if loss_name == 'cross-entropy':\n",
    "        loss = nn.CrossEntropyLoss(torch.tensor([weight, 1.], device=device), reduction=reduction)\n",
    "    elif loss_name == 'bce':\n",
    "        loss = BCE(reduction=reduction, pos_weight=torch.tensor([1/weight], device=device))\n",
    "    elif loss_name == 'mse':\n",
    "        loss = nn.MSELoss(reduction=reduction)\n",
    "    elif loss_name == 'focal':\n",
    "        loss = FocalLoss(reduction=reduction)\n",
    "    return loss.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_scheduler(opt, name, total_steps, lr):\n",
    "    if name == 'one-cycle':\n",
    "        sched = OneCycleLR(opt, lr, total_steps=total_steps)\n",
    "        sched.step_on_batch = True\n",
    "    elif name == 'cosine-anneal':\n",
    "        sched = CosineAnnealingLR(opt, total_steps)\n",
    "        sched.step_on_batch = True\n",
    "    elif name == 'reduce-on-plateau':\n",
    "        sched= ReduceLROnPlateau(opt)\n",
    "        sched.step_on_batch = False\n",
    "    else:\n",
    "        sched = None\n",
    "    return sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModule(pl.LightningModule):\n",
    "    def __init__(self, hparams, metrics=None):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.main_device = 'cpu' if hparams.gpus is None else f'cuda:{hparams.gpus[0]}'\n",
    "        try:\n",
    "            weight = hparams.weight if hparams.sample_mode == 0 else 1.\n",
    "        except AttributeError:\n",
    "            weight = 1.\n",
    "        self.loss = _get_loss(hparams.loss, weight, hparams.reduction, device=self.main_device)\n",
    "        self.bs = hparams.batch_size\n",
    "        self.lr = hparams.lr\n",
    "        self.wd = hparams.wd\n",
    "        self.metrics = ifnone(metrics, [])\n",
    "        model_type = 'normalizer' if isinstance(self, Normalizer) else 'classifier'\n",
    "        self.save_path = hparams.savedir/f'level_{hparams.level}/{model_type}/{hparams.model if model_type == \"classifier\" else hparams.normalizer}'\n",
    "        \n",
    "    def post_init(self):\n",
    "        self.leaf_modules = named_leaf_modules('', self)\n",
    "        self.sizes, self.leaf_modules = get_sizes(self, input_shape=(3, self.hparams.size, self.hparams.size), leaf_modules=self.leaf_modules)\n",
    "        self = self.to(self.main_device)\n",
    "        \n",
    "    def on_train_start(self):\n",
    "        self.train()\n",
    "        \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        lr = self.sched.optimizer.param_groups[-1]['lr']\n",
    "        log = {'train_loss': loss, 'learning_rate': lr}\n",
    "        return {'loss': loss, 'log': log}\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        log = {'val_loss': loss}\n",
    "        return {'val_loss': loss, 'log': log}\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'test_loss': self.loss(y_hat, y)}\n",
    "\n",
    "    \n",
    "    def test_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        return {'avg_test_loss': avg_loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        self.sched = _get_scheduler(opt, self.hparams.sched, self.hparams.epochs*len(self.train_dataloader()), self.lr)\n",
    "        return opt\n",
    "    \n",
    "    def on_after_backward(self):\n",
    "        for pg in self.sched.optimizer.param_groups:\n",
    "            for p in pg['params']: p.data.mul_(1 - self.wd*pg['lr'])\n",
    "    \n",
    "    def on_batch_end(self):\n",
    "        if self.sched is not None and self.sched.step_on_batch:\n",
    "            self.sched.step()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.sched is not None and not self.sched.step_on_batch:\n",
    "            self.sched.step()\n",
    "            \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        sm = self.hparams.sample_mode\n",
    "        w = self.hparams.weight\n",
    "        if sm > 0:\n",
    "            labels = self.data.train.labels == '1'\n",
    "            weights = np.where(labels, w, 1.)\n",
    "            if sm == 1:\n",
    "                sampler = WeightedRandomSampler(weights, 2*len(np.argwhere(~labels)))\n",
    "            else:\n",
    "                sampler = WeightedRandomSampler(weights, 2*len(np.argwhere(labels)), replacement=False)\n",
    "        else:\n",
    "            sampler = RandomSampler(self.data.train)\n",
    "        return DataLoader(self.data.train, batch_size=self.bs, sampler=sampler, drop_last=True)\n",
    "\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        # can also return a list of val dataloaders\n",
    "        return DataLoader(self.data.valid, batch_size=self.bs)\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        # can also return a list of test dataloaders\n",
    "        return DataLoader(self.data.test, batch_size=self.bs) if self.data.test is not None else None\n",
    "    \n",
    "    def load(self, version, ckpt_epoch=None):\n",
    "        save_dir = self.save_path/f'lightning_logs/version_{version}/checkpoints'\n",
    "        path = list(save_dir.iterdir())[-1] if ckpt_epoch is None else save_dir/f'_ckpt_epoch_{ckpt_epoch}.ckpt'\n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        self.load_state_dict(checkpoint['state_dict'])\n",
    "            \n",
    "    def my_summarize(self):\n",
    "        summary = pd.DataFrame({'Name': list(map(lambda x: x.name, self.leaf_modules)), 'Output Shape': self.sizes})\n",
    "        return summary\n",
    "    \n",
    "    def fit(self):\n",
    "        logger = CometLogger(api_key=os.environ['COMET_API_KEY'], workspace='schwobr', save_dir=self.save_path, project_name='grade-classif')\n",
    "        logger.experiment.add_tag('norm' if isinstance(self, Normalizer) else 'classif')\n",
    "        ckpt_path = self.save_path/'lightning_logs'/f'version_{logger.version}'/'checkpoints'\n",
    "        ckpt_callback = ModelCheckpoint(ckpt_path, save_top_k=3)\n",
    "        trainer = pl.Trainer(gpus=self.hparams.gpus, checkpoint_callback=ckpt_callback, logger=logger, min_epochs=self.hparams.epochs, max_epochs=self.hparams.epochs)\n",
    "        self.version = trainer.logger.version\n",
    "        trainer.fit(self)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.eval()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Normalizer(BaseModule):\n",
    "    def __init__(self, hparams, **kwargs):\n",
    "        super().__init__(hparams, **kwargs)\n",
    "        input_shape = (3, hparams.size, hparams.size)\n",
    "        self.unet = mods.DynamicUnet(hparams.normalizer, n_classes=3, input_shape=input_shape, pretrained=not hparams.rand_weights)\n",
    "        # meta = cnn_config(resnet34)\n",
    "        # body = create_body(resnet34, True, None)\n",
    "        # size = (224, 224)\n",
    "        # self.unet = models.unet.DynamicUnet(body, n_classes=3, img_size=size, blur=False, blur_final=True,\n",
    "        #      self_attention=False, y_range=None, norm_type=NormType, last_cross=True,\n",
    "        #      bottle=False)\n",
    "        tfms = get_transforms(hparams.size)\n",
    "        self.data = (NormDataset.\n",
    "                     from_folder(Path(hparams.data), extensions=['.png']).\n",
    "                     split_by_csv(hparams.data_csv).\n",
    "                     to_tensor(tfms=tfms))\n",
    "        self.post_init()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.unet(x)\n",
    "    \n",
    "    \n",
    "    def show_results(self, n=16, random=False, imgsize=4, title=None, **kwargs):\n",
    "        n = min(n, self.bs)\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(imgsize*3, imgsize*n))\n",
    "        idxs = np.random.choice(np.arange(len(self.data.valid)), size=n, replace=False)                \n",
    "        inputs = []\n",
    "        targs = []\n",
    "        for idx in idxs:\n",
    "            x, y = self.data.valid[idx]\n",
    "            inputs.append(x)\n",
    "            targs.append(y)            \n",
    "        inputs = torch.stack(inputs).to(next(self.parameters()).device)\n",
    "        preds = self.eval()(inputs).clamp(0, 1)\n",
    "        for ax_r, x, y, z in zip(axs, inputs, targs, preds):\n",
    "            x = x.cpu().numpy().transpose(1, 2, 0)\n",
    "            y = y.numpy().transpose(1, 2, 0)\n",
    "            z = z.detach().cpu().numpy().transpose(1, 2, 0)            \n",
    "            show_img(x, ax=ax_r[0])\n",
    "            show_img(y, ax=ax_r[1])\n",
    "            show_img(z, ax=ax_r[2])\n",
    "        title = ifnone(title, 'input/target/prediction')\n",
    "        fig.suptitle(title)\n",
    "        plt.show()\n",
    "        \n",
    "    def freeze_encoder(self):\n",
    "        for m in self.leaf_modules('', self):\n",
    "            if 'encoder' in m.name and not isinstance(m, nn.BatchNorm2d):\n",
    "                for param in m.parameters():\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "    def init_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                with torch.no_grad():\n",
    "                    m.bias.fill_(1e-3)\n",
    "                    m.weight.fill_(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grade_classif.params.parser import hparams\n",
    "from grade_classif.params.defaults import CSVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.data = Path('/data/DeepLearning/SCHWOB_Robin/Patches_normacolor_256/Patches_normacolor_256_1/')\n",
    "hparams.normalizer = 'resnet18'\n",
    "hparams.data_csv = CSVS/'normacolor_scans.csvs'\n",
    "hparams.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/DeepLearning/SCHWOB_Robin/Patches_normacolor_256/Patches_normacolor_256_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b862064d7c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f6ecaba9a098>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         self.data = (NormDataset.\n\u001b[0;32m---> 15\u001b[0;31m                      \u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                      \u001b[0msplit_by_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                      to_tensor(tfms=tfms))\n",
      "\u001b[0;32m/work/stages/schwob/grade_classif/nbs/grade_classif/data/dataset.py\u001b[0m in \u001b[0;36mfrom_folder\u001b[0;34m(cls, folder, id_column, recurse, extensions, include, exclude)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_label_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3G'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/stages/schwob/grade_classif/nbs/grade_classif/data/read.py\u001b[0m in \u001b[0;36mget_items\u001b[0;34m(folder, label_func, recurse, extensions, include, exclude, filterfunc)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfilterfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilterfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfilterfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/stages/schwob/.conda/envs/pytorch/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/stages/schwob/.conda/envs/pytorch/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/DeepLearning/SCHWOB_Robin/Patches_normacolor_256/Patches_normacolor_256_1'"
     ]
    }
   ],
   "source": [
    "norm = Normalizer(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.load('4ee731134a484fbfb27d5eebd1bd80ae', ckpt_epoch=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GradesClassifModel(BaseModule):\n",
    "    def __init__(self, hparams, **kwargs):\n",
    "        super().__init__(hparams, **kwargs)\n",
    "        tfms = get_transforms(hparams.size)\n",
    "        if hparams.concepts is not None and hparams.concept_classes is not None:\n",
    "            conc_classes_df = pd.read_csv(hparams.concept_classes, index_col=0)\n",
    "            if hparams.filt != 'all':\n",
    "                ok = conc_classes_df.loc[conc_classes_df['type'] == hparams.filt].index.values\n",
    "            else:\n",
    "                ok = conc_classes_df.loc[conc_classes_df['type'] != 'garb'].index.values\n",
    "            conc_df = pd.read_csv(hparams.concepts, index_col='patchId')\n",
    "            def filt(x):\n",
    "                return conc_df.loc[x.stem, 'concept'] in ok\n",
    "        else:\n",
    "            filt = None\n",
    "        self.data = (ImageClassifDataset.\n",
    "                     from_folder(Path(hparams.data), lambda x: x.parts[-3], classes=['1', '3'], extensions=['.png'], include=['1', '3'], open_mode=hparams.open_mode, filterfunc=filt).\n",
    "                     split_by_csv(hparams.data_csv).\n",
    "                     to_tensor(tfms=tfms, tfm_y=False))\n",
    "        weight = np.float32((self.data.train.labels == '3').sum()/(self.data.train.labels == '1').sum())\n",
    "        self.hparams.weight = weight\n",
    "        self.loss = _get_loss(hparams.loss, weight if hparams.sample_mode == 0 else 1., hparams.reduction, device=self.main_device)\n",
    "        if 'cbr' in hparams.model:\n",
    "            args = map(int, hparams.model.split('_')[1:])\n",
    "            base_model = mods.CBR(*args)\n",
    "            cut = -3\n",
    "        elif 'sasa' in hparams.model:\n",
    "            args = map(int, hparams.model.split('_')[1:])\n",
    "            base_model = mods.SASA(*args)\n",
    "            cut = -3\n",
    "        elif 'sanet' in hparams.model:\n",
    "            splits = hparams.model.split('_') \n",
    "            kernel_size = int(splits[-1])\n",
    "            base_model = getattr(mods, splits[0])(kernel_size)\n",
    "            cut = -2\n",
    "        else:\n",
    "            base_model = timm.create_model(hparams.model, pretrained=not hparams.rand_weights)\n",
    "            cut = -2\n",
    "        self.base_model = nn.Sequential(*list(base_model.children())[:cut])\n",
    "        head = [nn.AdaptiveAvgPool2d(1), nn.Flatten()]\n",
    "        nf = get_num_features(self.base_model)\n",
    "        p = hparams.dropout\n",
    "        nc = 2 if hparams.loss == 'cross-entropy' else 1\n",
    "        head += mods.bn_drop_lin(nf, nf, p=p/2) + mods.bn_drop_lin(nf, nc, p=p)\n",
    "        self.head = nn.Sequential(*head)\n",
    "        self.post_init()\n",
    "        self.create_normalizer()\n",
    "        \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        ret = {'val_loss': loss}\n",
    "        n = y.shape[0]\n",
    "        if self.hparams.loss == 'cross-entropy':\n",
    "            y_hat = torch.softmax(y_hat, dim=1)\n",
    "            y_hat = y_hat.argmax(dim=-1).view(n,-1)\n",
    "        else:\n",
    "            y_hat = torch.sigmoid(y_hat)\n",
    "            y_hat = (y_hat > 0.5).view(n, -1)\n",
    "        y = y.view(n,-1)\n",
    "        ret['tp'] = ((y_hat)&(y==1)).float().sum()\n",
    "        ret['tn'] = ((~y_hat)&(y==0)).float().sum()\n",
    "        ret['fp'] = ((y_hat)&(y==0)).float().sum()\n",
    "        ret['fn'] = ((~y_hat)&(y==1)).float().sum()\n",
    "        return ret\n",
    "        \n",
    "    def validation_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        log = {'val_loss': loss}\n",
    "        tp = torch.stack([x['tp'] for x in outputs]).sum()\n",
    "        fp = torch.stack([x['fp'] for x in outputs]).sum()\n",
    "        tn = torch.stack([x['tn'] for x in outputs]).sum()\n",
    "        fn = torch.stack([x['fn'] for x in outputs]).sum()\n",
    "        for metric in self.metrics:\n",
    "            try:\n",
    "                name = metric.__name__\n",
    "            except AttributeError:\n",
    "                name = metric.func.__name__\n",
    "                kws = metric.keywords\n",
    "                for k in kws:\n",
    "                    name += f'_{k}_{kws[k]}'\n",
    "            log[name] = metric(tp, fp, tn, fn)\n",
    "        return {'val_loss': loss, 'log': log}\n",
    "        \n",
    "    def create_normalizer(self):\n",
    "        hparams = self.hparams\n",
    "        if hparams.normalizer is not None:\n",
    "            norm = mods.DynamicUnet(hparams.normalizer, n_classes=3, input_shape=(3, hparams.size, hparams.size), pretrained=True)\n",
    "            if hparams.norm_version is not None:\n",
    "                save_dir = self.save_path.parents[1]/'normalizer'/f'{hparams.normalizer}/lightning_logs/version_{hparams.norm_version}/checkpoints'\n",
    "                path = next(save_dir.iterdir())\n",
    "                checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "                state_dict = {}\n",
    "                for k in checkpoint['state_dict']:\n",
    "                    state_dict[k.replace('unet.', '')] = checkpoint['state_dict'][k]\n",
    "                norm.load_state_dict(state_dict)\n",
    "                for p in norm.parameters():\n",
    "                    p.requires_grad = False\n",
    "            norm = norm.to(self.main_device)\n",
    "            self.norm = norm.__call__        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'norm'):\n",
    "            x = self.norm(x)\n",
    "        x = self.base_model(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pred = super().predict(x)\n",
    "        if self.hparams.loss == 'cross-entropy':\n",
    "            pred = torch.softmax(pred, dim=1)\n",
    "        else:\n",
    "            pred = torch.sigmoid(pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RNNAttention(BaseModule):\n",
    "    def __init__(self, hparams, **kwargs):\n",
    "        super().__init__(hparams, **kwargs)\n",
    "        tfms = get_transforms(hparams.size)\n",
    "        if hparams.concepts is not None and hparams.concept_classes is not None:\n",
    "            conc_classes_df = pd.read_csv(hparams.concept_classes, index_col=0)\n",
    "            if hparams.filt != 'all':\n",
    "                ok = conc_classes_df.loc[conc_classes_df['type'] == hparams.filt].index.values\n",
    "            else:\n",
    "                ok = conc_classes_df.loc[conc_classes_df['type'] != 'garb'].index.values\n",
    "            conc_df = pd.read_csv(hparams.concepts, index_col='patchId')\n",
    "            def filt(x):\n",
    "                return conc_df.loc[x.stem, 'concept'] in ok\n",
    "        else:\n",
    "            filt = None\n",
    "        self.data = (ImageClassifDataset.\n",
    "                     from_folder(Path(hparams.data), lambda x: x.parts[-3], classes=['1', '3'], extensions=['.png'], include=['1', '3'], open_mode=hparams.open_mode, filterfunc=filt).\n",
    "                     split_by_csv(hparams.data_csv).\n",
    "                     to_tensor(tfms=tfms, tfm_y=False))\n",
    "        \n",
    "        weight = np.float32((self.data.train.labels == '3').sum()/(self.data.train.labels == '1').sum())\n",
    "        self.hparams.weight = weight\n",
    "        self.loss = _get_loss(hparams.loss, weight if hparams.sample_mode == 0 else 1., hparams.reduction, device=self.main_device)\n",
    "\n",
    "        nc = 2 if hparams.loss == 'cross-entropy' else 1\n",
    "        self.t_x = nn.Sequential(*list(CBR(3, 64, 2).children())[:-1])\n",
    "        nf = get_num_features(self.t_x)\n",
    "        self.fc = nn.Linear(nx, nc)\n",
    "        self.t_l = nn.Sequential(nn.Linear(6, nf),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(nf, 2*nf),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(2*nf, nf))\n",
    "        self.t_a = nn.Sequential(nn.Linear(nf, 2*nf),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(2*nf, nf),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(nf, 6))\n",
    "        self.final_head = nn.Sequential(nn.Linear(nx*self.hparams.n_glimpses, nx),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(nf, nc))\n",
    "        \n",
    "        \n",
    "    def forward(self, X, l):     \n",
    "        Ai = gaussian_mask(*l[:3], self.hparams.glimpse_size, self.hparams.size)\n",
    "        Aj = gaussian_mask(*l[3:], self.hparams.glimpse_size, self.hparams.size)\n",
    "        x = Ai[None, None] @ X @ Aj.T[None, None]\n",
    "        if hasattr(self, 'norm'):\n",
    "            x = self.norm(x) \n",
    "        fx = self.t_x(x)\n",
    "        y = self.fc(fx)\n",
    "        fl = self.t_l(l)\n",
    "        l = torch.sigmoid(fx * fl)\n",
    "        l = self.t_a(l)\n",
    "        return fx, y, l\n",
    "    \n",
    "    def compute_loss(self, X, Y)\n",
    "        l0 = torch.tensor([0, .5, self.hparams.size//self.hparams.glimpse_size]*2, device=self.main_device)\n",
    "        loss = 0\n",
    "        loss_prev = 0\n",
    "        preds = []\n",
    "        for t in range(self.hparams.n_glimpses):            \n",
    "            fx, y_hat, l = self(X, l0)\n",
    "            fts.append(fx)\n",
    "            loss += self.loss(y_hat, Y)\n",
    "            loss_a = (y_hat**2).sum()\n",
    "            if t > 0:\n",
    "                loss -= loss_a - loss_prev / t\n",
    "            loss_prev += loss_a\n",
    "            loss += self.hparams.gamma * torch.exp(-torch.abs(l-l0))\n",
    "            l0 = l\n",
    "        # n_glimpses x bs x C\n",
    "        fts = torch.cat(fts)\n",
    "        fts = fts.view(fts.shape[1], -1)\n",
    "        Y_hat = self.final_head(fts)\n",
    "        loss += self.loss(Y_hat, Y)\n",
    "        return loss, Y_hat\n",
    "        \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        X, Y = batch\n",
    "        loss, _ = self.compute_loss(X, Y)\n",
    "        lr = self.sched.optimizer.param_groups[-1]['lr']\n",
    "        log = {'train_loss': loss, 'learning_rate': lr}\n",
    "        return {'loss': loss, 'log': log}\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        loss, y_hat = self.compute_loss(x, y)\n",
    "        ret = {'val_loss': loss}\n",
    "        n = y.shape[0]\n",
    "        if self.hparams.loss == 'cross-entropy':\n",
    "            y_hat = torch.softmax(y_hat, dim=1)\n",
    "            y_hat = y_hat.argmax(dim=-1).view(n,-1)\n",
    "        else:\n",
    "            y_hat = torch.sigmoid(y_hat)\n",
    "            y_hat = (y_hat > 0.5).view(n, -1)\n",
    "        y = y.view(n,-1)\n",
    "        ret['tp'] = ((y_hat)&(y==1)).float().sum()\n",
    "        ret['tn'] = ((~y_hat)&(y==0)).float().sum()\n",
    "        ret['fp'] = ((y_hat)&(y==0)).float().sum()\n",
    "        ret['fn'] = ((~y_hat)&(y==1)).float().sum()\n",
    "        return ret\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        log = {'val_loss': loss}\n",
    "        tp = torch.stack([x['tp'] for x in outputs]).sum()\n",
    "        fp = torch.stack([x['fp'] for x in outputs]).sum()\n",
    "        tn = torch.stack([x['tn'] for x in outputs]).sum()\n",
    "        fn = torch.stack([x['fn'] for x in outputs]).sum()\n",
    "        for metric in self.metrics:\n",
    "            try:\n",
    "                name = metric.__name__\n",
    "            except AttributeError:\n",
    "                name = metric.func.__name__\n",
    "                kws = metric.keywords\n",
    "                for k in kws:\n",
    "                    name += f'_{k}_{kws[k]}'\n",
    "            log[name] = metric(tp, fp, tn, fn)\n",
    "        return {'val_loss': loss, 'log': log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
