{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "> Functions that wrap the whole training processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from grade_classif.imports import *\n",
    "from grade_classif.models.metrics import accuracy, f_1, precision, recall\n",
    "from grade_classif.models.plmodules import (\n",
    "    ImageClassifDataModule,\n",
    "    ClassifModel,\n",
    "    Normalizer,\n",
    "    NormDataModule,\n",
    "    MILModel,\n",
    "    MILDataModule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_normalizer(hparams: Namespace) -> Normalizer:\n",
    "    hparams = vars(hparams)\n",
    "    dm = NormDataModule(**hparams)\n",
    "    model = Normalizer(**hparams)\n",
    "    # model.freeze_encoder()\n",
    "    model.fit(dm)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains a `Normalizer` unet with parameters defined in `hparams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_classifier(hparams: Namespace) -> ClassifModel:\n",
    "    hparams = vars(hparams)\n",
    "    classes = [\"1\", \"3\"]\n",
    "    dm = ImageClassifDataModule(classes=classes, label_func=lambda x: x.parts[-3], **hparams)\n",
    "    model = ClassifModel(\n",
    "        classes=classes,\n",
    "        n_classes=len(classes),\n",
    "        **hparams,\n",
    "        metrics=[accuracy]\n",
    "        + [\n",
    "            met\n",
    "            for i in range(2)\n",
    "            for met in (\n",
    "                partial(precision, cat=i),\n",
    "                partial(recall, cat=i),\n",
    "                partial(f_1, cat=i),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    model.fit(dm)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains a `GradesClassifModel` for grade classifications with parameters defined in `hparams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_discriminator(hparams: Namespace) -> ClassifModel:\n",
    "    classes = [\"04\", \"05\", \"08\"]\n",
    "    def _label_func(x):\n",
    "        for cl in classes:\n",
    "            if f\"PACS{cl}\" in x.name:\n",
    "                return cl\n",
    "    hparams = vars(hparams)\n",
    "    dm = ImageClassifDataModule(classes=classes, label_func=_label_func, **hparams)\n",
    "    model = ClassifModel(\n",
    "        classes=classes,\n",
    "        n_classes=len(classes),\n",
    "        **hparams,\n",
    "        metrics=[accuracy] + [met for met in (precision, recall, f_1)]\n",
    "    )\n",
    "    model.fit(dm)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_cancer_detector(hparams: Namespace) -> ClassifModel:\n",
    "    hparams = vars(hparams)\n",
    "    classes = [\"artefact\", \"cancer\", \"non_cancer\"]\n",
    "    dm = ImageClassifDataModule(\n",
    "        classes=classes,\n",
    "        label_func=lambda x: x.parent.name,\n",
    "        get_id=lambda x: \"_\".join(x.name.split(\"_\")[:-2]),\n",
    "        **hparams\n",
    "    )\n",
    "    model = ClassifModel(\n",
    "        classes=classes,\n",
    "        n_classes=len(classes),\n",
    "        **hparams,\n",
    "        metrics=[accuracy] + [met for met in (precision, recall, f_1)]\n",
    "    )\n",
    "    model.fit(dm)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_mil_cancer_detector(hparams: Namespace) -> MILModel:\n",
    "    hparams = vars(hparams)\n",
    "    dm = MILDataModule(classes=[\"None\", \"Infilt\"], **hparams)\n",
    "    model = MILModel(\n",
    "        **hparams,\n",
    "        metrics=[accuracy]\n",
    "        + [\n",
    "            met\n",
    "            for i in range(2)\n",
    "            for met in (\n",
    "                partial(precision, cat=i),\n",
    "                partial(recall, cat=i),\n",
    "                partial(f_1, cat=i),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    model.fit(dm, num_sanity_val_steps=0, reload_dataloaders_every_epoch=True)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_mil_reargmt(hparams: Namespace) -> MILModel:\n",
    "    hparams = vars(hparams)\n",
    "    dm = MILDataModule(\n",
    "        classes=[\"NoReargmt\", \"DHL_THL\"],\n",
    "        extensions=[\".mrxs\", \".svs\"],\n",
    "        label_func=lambda x: x.parts[-3],\n",
    "        **hparams\n",
    "    )\n",
    "    model = MILModel(\n",
    "        **hparams,\n",
    "        metrics=[accuracy]\n",
    "        + [\n",
    "            met\n",
    "            for i in range(2)\n",
    "            for met in (\n",
    "                partial(precision, cat=i),\n",
    "                partial(recall, cat=i),\n",
    "                partial(f_1, cat=i),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    model.fit(dm, num_sanity_val_steps=0, reload_dataloaders_every_epoch=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grade_classif.params.parser import hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(hparams.concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(hparams.concept_classes, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grade_classif.data.dataset import ImageClassifDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.concepts is not None and hparams.concept_classes is not None:\n",
    "    conc_classes_df = pd.read_csv(hparams.concept_classes, index_col=0)\n",
    "    ok = conc_classes_df.loc[conc_classes_df[\"type\"] == \"K_inter\"].index.values\n",
    "    conc_df = pd.read_csv(hparams.concepts, index_col=\"patchId\")\n",
    "\n",
    "    def filt(x):\n",
    "        return conc_df.loc[x.stem, \"concept\"] in ok\n",
    "\n",
    "\n",
    "else:\n",
    "    filt = None\n",
    "filt = None\n",
    "data = (\n",
    "    ImageClassifDataset.from_folder(\n",
    "        Path(hparams.data),\n",
    "        lambda x: x.parts[-3],\n",
    "        classes=[\"1\", \"3\"],\n",
    "        extensions=[\".png\"],\n",
    "        include=[\"1\", \"3\"],\n",
    "        open_mode=\"3G\",\n",
    "        filterfunc=filt,\n",
    "    )\n",
    "    .split_by_csv(hparams.data_csv)\n",
    "    .to_tensor(tfm_y=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = len(np.argwhere(labels == \"1\"))\n",
    "n3 = len(np.argwhere(labels == \"3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.067571469823852"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n3 / n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COMET_API_KEY\"] = \"4p7hCzb8hjWG7Qb8CtNRRQkcG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_train.ipynb.\n",
      "Converted 02_predict.ipynb.\n",
      "Converted 10_data.read.ipynb.\n",
      "Converted 11_data.loaders.ipynb.\n",
      "Converted 12_data.dataset.ipynb.\n",
      "Converted 13_data.utils.ipynb.\n",
      "Converted 14_data.transforms.ipynb.\n",
      "Converted 15_data.color.ipynb.\n",
      "Converted 20_models.plmodules.ipynb.\n",
      "Converted 21_models.modules.ipynb.\n",
      "Converted 22_models.utils.ipynb.\n",
      "Converted 23_models.hooks.ipynb.\n",
      "Converted 24_models.metrics.ipynb.\n",
      "Converted 25_models.losses.ipynb.\n",
      "Converted 80_params.defaults.ipynb.\n",
      "Converted 81_params.parser.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
